{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Insurance Company Benchmark CLasificador"
      ],
      "metadata": {
        "id": "XmFh-p4Q73AK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Librerías que se van a utilizar:"
      ],
      "metadata": {
        "id": "i3s68kABkIOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score,confusion_matrix, make_scorer, f1_score, log_loss, hinge_loss\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning"
      ],
      "metadata": {
        "id": "dWdFcdhakDXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar completamente este documento no es instantáneo, lleva algunos minutos, entorno a 5 minutos, pero siempre termina de ejecutarse, no se queda de forma indefinida y siempre termina mucho antes de llegar a los 10 minutos."
      ],
      "metadata": {
        "id": "if79I1ixuy4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>1)  Analizar y describir adecuadamente el problema a resolver. Identificar los elementos $X$, $Y$ and $f$ del problema, y describirlos en detalle. 0.5 puntos."
      ],
      "metadata": {
        "id": "Y2HSMffMUP10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este problema de clasificación binaria se trata de, a partir de las muestras de entrenamiento y test obtenidas de una base de datos proporcionada, donde cada muestra contiene información sobre un cliente de la compañia de seguros, se busca aprender una función $g$ que clasifique cada muestra como poseedor de una poliza de seguros de Caravana o no poseedor de una poliza de Caravana (El problema originalmente consistía en estimar el número de polizas de Caravana de cada muestra y ha sido modificado a estimar si tiene 1 o 0 polizas debido a las características de la salida de la base de datos).\n",
        "   \n",
        "Cada muestra posee 85 atributos, cada uno representando un dato del cliente, y una etiqueta representando si tiene o no poliza de Caravana. Por lo tanto cada muestra $n$ se identificará como un vector $x_n$ con 85 valores que son todos números y tiene una etiqueta asociada representada por un valor $y \\in \\{0,1\\}$, con $0$ para representar que no tiene poliza y $1$ para representar que tiene una poliza. Entonces $X$ será el vector de muestras $x_n$ y el elemento $Y$ será el vector de etiquetas $y$.\n",
        "  \n",
        "Para aprender la función $g$ se empleará un algoritmo de aprendizaje automático que utilice el conjunto de entrenamiento para ajustar el vector $w$ de prámetros (pesos) del modelo (sobre una clase de funciones $\\mathcal{H}$), minimizando el error asociado al algoritmo de las soluciones calculadas. Como resultado de aplicar el algoritmo al problema, obtendremos una función $g$ solución que para cualquier muestra $x$ del espacio total de las posibles muestras, nos proporcione una etiqueta $y$ que será la predicción de la clasificación de la muestra. Finalmente se utilizará el conjunto de muestras de test para evaluar el error fuera de la muestra de entrenamiento.   \n",
        "\n",
        "Durante el proceso de aprendizaje el conjunto de datos puede modificarse, tratando de no afectar la importancia e información que ofrecen los datos, para obtener mejores resultados a la hora de aplicar los algorimtos de aprendizaje automático que utilicemos para encontrar el mejor clasificador para el problema."
      ],
      "metadata": {
        "id": "CEpiie784Ku0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todas las variables del conjunto de datos son:\n",
        "\n",
        "| Nr | Name    | Description                                   |\n",
        "|----|---------|-----------------------------------------------|\n",
        "| 1  | MOSTYPE | Customer Subtype see L0                       |\n",
        "| 2  | MAANTHUI | Number of houses 1 – 10                       |\n",
        "| 3  | MGEMOMV  | Avg size household 1 – 6                       |\n",
        "| 4  | MGEMLEEF | Avg age see L1                                 |\n",
        "| 5  | MOSHOOFD | Customer main type see L2                      |\n",
        "| 6  | MGODRK  | Roman catholic see L3                          |\n",
        "| 7  | MGODPR  | Protestant ...                                 |\n",
        "| 8  | MGODOV  | Other religion                                 |\n",
        "| 9  | MGODGE  | No religion                                    |\n",
        "| 10 | MRELGE  | Married                                        |\n",
        "| 11 | MRELSA  | Living together                                |\n",
        "| 12 | MRELOV  | Other relation                                 |\n",
        "| 13 | MFALLEEN | Singles                                        |\n",
        "| 14 | MFGEKIND | Household without children                     |\n",
        "| 15 | MFWEKIND | Household with children                        |\n",
        "| 16 | MOPLHOOG | High level education                           |\n",
        "| 17 | MOPLMIDD | Medium level education                         |\n",
        "| 18 | MOPLLAAG | Lower level education                          |\n",
        "| 19 | MBERHOOG | High status                                    |\n",
        "| 20 | MBERZELF | Entrepreneur                                   |\n",
        "| 21 | MBERBOER | Farmer                                         |\n",
        "| 22 | MBERMIDD | Middle management                              |\n",
        "| 23 | MBERARBG | Skilled labourers                              |\n",
        "| 24 | MBERARBO | Unskilled labourers                            |\n",
        "| 25 | MSKA    | Social class A                                 |\n",
        "| 26 | MSKB1   | Social class B1                                |\n",
        "| 27 | MSKB2   | Social class B2                                |\n",
        "| 28 | MSKC    | Social class C                                 |\n",
        "| 29 | MSKD    | Social class D                                 |\n",
        "| 30 | MHHUUR  | Rented house                                   |\n",
        "| 31 | MHKOOP  | Home owners                                    |\n",
        "| 32 | MAUT1   | 1 car                                          |\n",
        "| 33 | MAUT2   | 2 cars                                         |\n",
        "| 34 | MAUT0   | No car                                         |\n",
        "| 35 | MZFONDS | National Health Service                        |\n",
        "| 36 | MZPART  | Private health insurance                       |\n",
        "| 37 | MINKM30 | Income < 30.000                                |\n",
        "| 38 | MINK3045 | Income 30-45.000                               |\n",
        "| 39 | MINK4575 | Income 45-75.000                               |\n",
        "| 40 | MINK7512 | Income 75-122.000                              |\n",
        "| 41 | MINK123M | Income >123.000                                |\n",
        "| 42 | MINKGEM | Average income                                 |\n",
        "| 43 | MKOOPKLA | Purchasing power class                         |\n",
        "| 44 | PWAPART | Contribution private third party insurance L4  |\n",
        "| 45 | PWABEDR | Contribution third party insurance (firms) ... |\n",
        "| 46 | PWALAND | Contribution third party insurane (agriculture)|\n",
        "| 47 | PPERSAUT | Contribution car policies                      |\n",
        "| 48 | PBESAUT | Contribution delivery van policies             |\n",
        "| 49 | PMOTSCO | Contribution motorcycle/scooter policies       |\n",
        "| 50 | PVRAAUT | Contribution lorry policies                    |\n",
        "| 51 | PAANHANG | Contribution trailer policies                  |\n",
        "| 52 | PTRACTOR | Contribution tractor policies                  |\n",
        "| 53 | PWERKT  | Contribution agricultural machines policies    |\n",
        "| 54 | PBROM   | Contribution moped policies                    |\n",
        "| 55 | PLEVEN  | Contribution life insurances                   |\n",
        "| 56 | PPERSONG | Contribution private accident insurance policies |\n",
        "| 57 | PGEZONG  | Contribution family accidents insurance policies |\n",
        "| 58 | PWAOREG  | Contribution disability insurance policies     |\n",
        "| 59 | PBRAND  | Contribution fire policies                     |\n",
        "| 60 | PZEILPL | Contribution surfboard policies                |\n",
        "| 61 | PPLEZIER | Contribution boat policies                     |\n",
        "| 62 | PFIETS  | Contribution bicycle policies                  |\n",
        "| 63 | PINBOED | Contribution property insurance policies       |\n",
        "| 64 | PBYSTAND | Contribution social security insurance policies|\n",
        "| 65 | AWAPART | Number of private third party insurance 1 - 12 |\n",
        "| 66 | AWABEDR | Number of third party insurance (firms) ...    |\n",
        "| 67 | AWALAND | Number of third party insurane (agriculture)   |\n",
        "| 68 | APERSAUT | Number of car policies                         |\n",
        "| 69 | ABESAUT | Number of delivery van policies                |\n",
        "| 70 | AMOTSCO | Number of motorcycle/scooter policies          |\n",
        "| 71 | AVRAAUT | Number of lorry policies                       |\n",
        "| 72 | AAANHANG | Number of trailer policies                     |\n",
        "| 73 | ATRACTOR | Number of tractor policies                     |\n",
        "| 74 | AWERKT  | Number of agricultural machines policies       |\n",
        "| 75 | ABROM   | Number of moped policies                       |\n",
        "| 76 | ALEVEN  | Number of life insurances                      |\n",
        "| 77 | APERSONG | Number of private accident insurance policies  |\n",
        "| 78 | AGEZONG  | Number of family accidents insurance policies  |\n",
        "| 79 | AWAOREG  | Number of disability insurance policies        |\n",
        "| 80 | ABRAND  | Number of fire policies                        |\n",
        "| 81 | AZEILPL | Number of surfboard policies                    |\n",
        "| 82 | APLEZIER | Number of boat policies                         |\n",
        "| 83 | AFIETS  | Number of bicycle policies                      |\n",
        "| 84 | AINBOED | Number of property insurance policies           |\n",
        "| 85 | ABYSTAND | Number of social security insurance policies    |\n",
        "| 86 | CARAVAN | Number of mobile home policies 0 - 1            |\n",
        "\n",
        "\n",
        "\n",
        "| L0 | Value Label                         |\n",
        "|----|------------------------------------|\n",
        "| 1  | High Income, expensive child        |\n",
        "| 2  | Very Important Provincials          |\n",
        "| 3  | High status seniors                 |\n",
        "| 4  | Affluent senior apartments          |\n",
        "| 5  | Mixed seniors                       |\n",
        "| 6  | Career and childcare                |\n",
        "| 7  | Dinki's (double income no kids)     |\n",
        "| 8  | Middle class families               |\n",
        "| 9  | Modern, complete families           |\n",
        "| 10 | Stable family                       |\n",
        "| 11 | Family starters                     |\n",
        "| 12 | Affluent young families             |\n",
        "| 13 | Young all american family           |\n",
        "| 14 | Junior cosmopolitan                 |\n",
        "| 15 | Senior cosmopolitans                |\n",
        "| 16 | Students in apartments              |\n",
        "| 17 | Fresh masters in the city           |\n",
        "| 18 | Single youth                        |\n",
        "| 19 | Suburban youth                       |\n",
        "| 20 | Ethnically diverse                  |\n",
        "| 21 | Young urban have-nots               |\n",
        "| 22 | Mixed apartment dwellers             |\n",
        "| 23 | Young and rising                    |\n",
        "| 24 | Young, low educated                  |\n",
        "| 25 | Young seniors in the city           |\n",
        "| 26 | Own home elderly                    |\n",
        "| 27 | Seniors in apartments               |\n",
        "| 28 | Residential elderly                 |\n",
        "| 29 | Porchless seniors: no front yard    |\n",
        "| 30 | Religious elderly singles           |\n",
        "| 31 | Low income catholics                 |\n",
        "| 32 | Mixed seniors                        |\n",
        "| 33 | Lower class large families           |\n",
        "| 34 | Large family, employed child         |\n",
        "| 35 | Village families                     |\n",
        "| 36 | Couples with teens 'Married with children'|\n",
        "| 37 | Mixed small town dwellers           |\n",
        "| 38 | Traditional families                |\n",
        "| 39 | Large religous families              |\n",
        "| 40 | Large family farms                   |\n",
        "| 41 | Mixed rurals                         |\n",
        "\n",
        "\n",
        "| L2 | Label                    |\n",
        "|----|--------------------------|\n",
        "| 1  | Successful hedonists     |\n",
        "| 2  | Driven Growers           |\n",
        "| 3  | Average Family           |\n",
        "| 4  | Career Loners            |\n",
        "| 5  | Living well              |\n",
        "| 6  | Cruising Seniors         |\n",
        "| 7  | Retired and Religeous    |\n",
        "| 8  | Family with grown ups    |\n",
        "| 9  | Conservative families    |\n",
        "| 10 | Farmers                  |\n",
        "\n",
        "| L3 | Label |\n",
        "|-------|-------|\n",
        "| 0     | 0%    |\n",
        "| 1     | 1 - 10%   |\n",
        "| 2     | 11 - 23%  |\n",
        "| 3     | 24 - 36%  |\n",
        "| 4     | 37 - 49%  |\n",
        "| 5     | 50 - 62%  |\n",
        "| 6     | 63 - 75%  |\n",
        "| 7     | 76 - 88%  |\n",
        "| 8     | 89 - 99%  |\n",
        "| 9     | 100%   |\n",
        "\n",
        "| L4 | Label                |\n",
        "|-------|----------------------|\n",
        "| 0     | 0                    |\n",
        "| 1     | 1 - 49               |\n",
        "| 2     | 50 - 99              |\n",
        "| 3     | 100 - 199            |\n",
        "| 4     | 200 - 499            |\n",
        "| 5     | 500 - 999            |\n",
        "| 6     | 1000 - 4999          |\n",
        "| 7     | 5000 - 9999          |\n",
        "| 8     | 10.000 - 19.999      |\n",
        "| 9     | 20.000 - ?            |\n",
        "\n"
      ],
      "metadata": {
        "id": "8fzRMTzXbLPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Acceder a los datos:"
      ],
      "metadata": {
        "id": "dbc8dfqr-26R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Para acceder a nuestros ficheros de Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# La carpeta datos (que contiene X_train.npy, y_train.npy, X_test.npy y y_test.npy)\n",
        "# debe estar en vuestro Drive, dentro de la carpeta 'Colab Notebooks'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW4AUpWO-oKC",
        "outputId": "aeb6d39f-42da-437c-9bdb-ad867806ff5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los datos están separados en dos partes, una para entrenamiento y otra para test. Se cargan los datos y se unen en un conjunto para poder hacer la propia partición de los datos para entrenamiento y test:"
      ],
      "metadata": {
        "id": "RK89e_0rjrFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Primera parte de los datos (parte de entrenamiento)\n",
        "file_path = 'drive/MyDrive/Colab Notebooks/datos/ticdata2000.txt'\n",
        "\n",
        "datos = np.loadtxt(file_path, delimiter='\\t')#Funcion cargar datos desde txt\n",
        "\n",
        "x1 = datos[:, :-1]  # todas las columnas excepto la última\n",
        "y1 = datos[:, -1]   # ultima columna donde estan las etiquetas\n",
        "x1 = np.array(x1, np.float64)\n",
        "y1 = np.array(y1, np.float64)\n",
        "\n",
        "#Segunda parte de los datos (separados para test)\n",
        "file_path = 'drive/MyDrive/Colab Notebooks/datos/ticeval2000.txt' #Vector de muestras sin las etiquetas\n",
        "x2 = np.loadtxt(file_path, delimiter='\\t')#Funcion cargar datos desde txt\n",
        "file_path = 'drive/MyDrive/Colab Notebooks/datos/tictgts2000.txt' #Vector de muestras sin las etiquetas\n",
        "y2 = np.loadtxt(file_path, delimiter='\\t')#Funcion cargar datos desde txt\n",
        "x2 = np.array(x2, np.float64)\n",
        "y2 = np.array(y2, np.float64)\n",
        "\n",
        "#Unir datos\n",
        "x = np.row_stack((x1,x2))\n",
        "y = np.concatenate((y1,y2))\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "# Mostrar dimension del conjunto de muestras total\n",
        "print(\"Forma de vector X de muestras:\", x.shape)\n",
        "print(\"Forma de vector X de etiquetas:\", y.shape)\n"
      ],
      "metadata": {
        "id": "Lm9cT0xof1-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a21e509-a760-40d1-eb34-729e71052b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de vector X de muestras: (9822, 85)\n",
            "Forma de vector X de etiquetas: (9822,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que tenemos un total de 9822 muestras en nuestro conunto de datos y para cada muestra poseemos un total de 85 variables más la etiqueta de cada muestra."
      ],
      "metadata": {
        "id": "5sNNCB29g3Bx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de obtener el conjunto total de datos separamos los datos en un conjunto de entrenamiento y otro de test. Realizamos esto lo primero para evitar observar los datos de test y realizar \"Data Snooping\" donde el conjunto de datos podría influenciar nuestra elección sobre el modelo a utilizar para resolver el problema de aprendizaje automático. Para separar las muestras en train y test, dos distribuciones muy comunes en la práctica son 70% de train y 30% de test, y 80% de train y 20% de test. Al utilizar una distribución 70-30 obtendríamos una estimación mejor del error $E_{out}$ a partir del error $E_{test}$ que con la de 80-20, ya que se utilizaría un número mayor de muestras para obtener la estimación, un 30% del total, que en la otra distribución que usaría un 20% del total. Sin embargo, al utilizar una distribución 80-20 obtendríamos un mejor ajuste del problema al entrenar el modelo de aprendizaje con más datos que con la otra distribución, teniendo una mejor generalización en el conjunto de entrenamiento de la función que tratamos de aproximar. En general cuantos más datos se utilicen en test mejor será la estimación del error  $E_{out}$ y cuantos más datos se utilicen en el entrenamiento, el clasificador calculado se ajustará mejor al problema, ya que tiene más datos con los que aprender.  \n",
        "En este caso he elegido una distribución de 80% para entrenamiento y 20% de test, teniendo en cuenta que con esta distribución se tiene un número menor de datos para estimar el error  $E_{out}$, pero se tiene un número mayor de datos para entrenar y para utilizar Cross-Validation con un conjunto de datos mayor."
      ],
      "metadata": {
        "id": "qJRxc5lLpbEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "trainPortion = 0.8 #porcentaje de train, el porcentaje de test será la resta de 1 menos el porcentaje de train\n",
        "\n",
        "#-------------Obtener índices\n",
        "\n",
        "indexesData = np.arange(len(y)) #Indices del conjunto de muestras\n",
        "#-------------Desordenar indices y separar en rain y test\n",
        "\n",
        "np.random.shuffle(indexesData) #Desordenar indices de las muestras\n",
        "numberTrain = round(len(indexesData)*trainPortion) #numero de muestras para train\n",
        "trainIndexes = indexesData[:numberTrain]\n",
        "testIndexes = indexesData[numberTrain:]\n",
        "\n",
        "#-------------Datos desorden:ados para train y test\n",
        "\n",
        "trainX = x[trainIndexes]\n",
        "testX = x[testIndexes]\n",
        "trainY = y[trainIndexes]\n",
        "testY = y[testIndexes]\n",
        "\n",
        "#-------------Copia de los datos para mantener datos originales después del preprocesado\n",
        "\n",
        "original_trainX = trainX.copy()\n",
        "original_testX = testX.copy()\n",
        "original_trainY = trainY.copy()\n",
        "original_testY = testY.copy()\n",
        "\n",
        "#-------------Mostrar resultados\n",
        "\n",
        "print('Muestras totales:  {}'.format(len(trainY)+len(testX)))\n",
        "print('Muestras train:  {}'.format(len(trainY)))\n",
        "print('Muestras test:  {}'.format(len(testX)))\n"
      ],
      "metadata": {
        "id": "6nXUieJWpv2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f831ccb-f5ef-40cb-9202-b73db2794974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muestras totales:  9822\n",
            "Muestras train:  7858\n",
            "Muestras test:  1964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se podría utilizar la función `train_test_split()` de scikit-learn que ofrece un comportamiento similar al código implementado. Como podemos observar, tenemos un total de 9822 muestras, de los cuales 7858 , que representan el 80% del total, serán utilizados para entrenamiento y el resto 1964 (20% del total) para test."
      ],
      "metadata": {
        "id": "pxH0FJXoCkVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Desbalanceo de clases:**"
      ],
      "metadata": {
        "id": "DglU3G8YRso-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a observar el número total de muestras por clase para ver si las clases están debalanceadas en cuanto al número de muestras en el conjunto de entrenamiento (el conjunto de test no lo utilizamos hasta que tengamos que evaluar la mejor hipótesis seleccionada, para evitar realizar Data-Snooping):"
      ],
      "metadata": {
        "id": "TSNaMLkmGIlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['No Poseedor de Poliza (0)', 'Poseedor de Poliza (1)']\n",
        "\n",
        "#Contar muestras por clase:\n",
        "class_num = []\n",
        "for i in np.unique(trainY):\n",
        "  class_num.append(np.count_nonzero(trainY== i))\n",
        "class_num = np.array(class_num)\n",
        "\n",
        "# Mostrar bar plot de las clases\n",
        "fig = plt.figure(figsize=(6,5))\n",
        "plt.bar(class_names,class_num)#crear un grafico de barras\n",
        "#plt.legend(loc='upper right') #añadir la leyenda al plot\n",
        "plt.title('Número de muestras por clase')\n",
        "plt.show()\n",
        "\n",
        "#Mostar porcentajes y número de muestras\n",
        "print('Muestras totales en entrenamiento:  {}'.format(len(trainY)))\n",
        "for i in range(len(class_num)):\n",
        "  print('--- Clase {} ---'.format(i))\n",
        "  print('Muestras en train:  {}'.format(class_num[i]))\n",
        "  print('Porcentaje en train:  {}%'.format(np.round(100*class_num[i]/len(trainY),2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "1d4plvGeV0TW",
        "outputId": "258ad2e3-b5a4-43ec-b4fa-2419b8f7799b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAHDCAYAAACagEirAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLNUlEQVR4nO3dd1gUV8M28Ju2y1J2sQALEQUlKhhL1CjYC7oaNBassaCiRoMaNFhI7CbWGKOJ3Sg+T/QxlmgUIojdKDbUiA17IFGwIKyogLDn+8OPeVkpwgjBJPfvuubSPefMmTOz7d5pmAghBIiIiIiKybSsB0BERER/TwwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJAtDBBEREcnCEEFERESyMETQ397x48cxY8YMPHjwoKyHQkT0r8IQQX9riYmJ6Nq1K0xNTVGxYsWyHs5f4vbt2zAxMUFoaGhZD4X+xlxdXTFo0KCyHgb9zTFEUJkKDQ2FiYkJLC0t8eeff+apb9WqFd555518583Ozkbfvn3xwQcfYMqUKaU9VHrDXLp0CdOnT8ft27fLeihE/1oMEfRGyMjIwNy5c4s1T1xcHHx9fbF8+fJSGhW9yS5duoQZM2YwRBCVIYYIeiPUq1cPq1evxp07d4o8j6enJ4KDg2FmZlaKI5PHYDAgPT29rIdB/58QAs+ePSvrYZSY9PR0GAyGsh4GEUMEvRk+++wzZGdnv3JvRGHnA5iYmGD69OnS4+nTp8PExARXr15F//79odFoYG9vjylTpkAIgYSEBHTp0gVqtRparRYLFy7M02dGRgamTZsGd3d3KJVKuLi4YMKECcjIyMiz7FGjRmHDhg2oVasWlEolIiIiAABnz55Fx44doVarYWNjg7Zt2+L48eNF2i4pKSkYNGgQNBoN7Ozs4O/vj5SUlHzbXrlyBT169ED58uVhaWmJhg0bYufOna9cRs42/eqrr7B06VJUrVoVVlZWaN++PRISEiCEwKxZs1CpUiWoVCp06dIFycnJedY/97bPkd9x95SUFAQFBcHFxQVKpRLu7u6YN29eni/FTZs2oUGDBrC1tYVarUbt2rWxePFiAC8Og/Xs2RMA0Lp1a5iYmMDExAQHDx6UltupUydERkaiYcOGUKlUWLlyJQBg3bp1aNOmDRwcHKBUKuHp6Znv3qzTp09Dp9OhYsWKUKlUcHNzw5AhQ165PXOWvWfPHtSrVw+Wlpbw9PTETz/9lKftzZs30bNnT5QvXx5WVlbw8vJCeHi4UZuDBw/CxMQEmzZtwuTJk/HWW2/BysoKer2+wDEYDAYsXrwYtWvXhqWlJezt7dGhQwecPn26wHmSk5MRHByM2rVrw8bGBmq1Gh07dsRvv/2Wp+23336LWrVqwcrKCuXKlUPDhg2xceNGozZ//vknhgwZAkdHRyiVStSqVQtr16591eajvxnzsh4AEQC4ublh4MCBWL16NSZNmgRnZ+cS67t3797w8PDA3LlzER4eji+++ALly5fHypUr0aZNG8ybNw8bNmxAcHAw3nvvPbRo0QLAiw/iDz74AL/++iuGDx8ODw8PxMbGYtGiRbh69Sp27NhhtJz9+/dj8+bNGDVqFCpWrAhXV1dcvHgRzZs3h1qtxoQJE2BhYYGVK1eiVatWOHToEBo3blzguIUQ6NKlC3799VeMGDECHh4e2L59O/z9/fO0vXjxIpo2bYq33noLkyZNgrW1NTZv3oyuXbti27Zt6Nat2yu304YNG5CZmYnRo0cjOTkZ8+fPR69evdCmTRscPHgQEydOxPXr1/Htt98iODhY1hfC06dP0bJlS/z555/46KOPULlyZRw7dgwhISG4e/cuvvnmGwBAVFQU+vbti7Zt22LevHkAgMuXL+Po0aP45JNP0KJFC4wZMwZLlizBZ599Bg8PDwCQ/gVeHO7q27cvPvroIwwbNgw1atQAACxfvhy1atXCBx98AHNzc+zatQsff/wxDAYDAgMDAQD37t1D+/btYW9vj0mTJsHOzg63b9/ONwjk59q1a+jduzdGjBgBf39/rFu3Dj179kRERATatWsHAEhKSkKTJk3w9OlTjBkzBhUqVMD69evxwQcfYOvWrXmes1mzZkGhUCA4OBgZGRlQKBQFLj8gIAChoaHo2LEjhg4diqysLBw5cgTHjx9Hw4YN853n5s2b2LFjB3r27Ak3NzckJSVh5cqVaNmyJS5duiS9J1evXo0xY8agR48e+OSTT5Ceno7z58/jxIkT+PDDD6V18/LyksK1vb09du/ejYCAAOj1egQFBRVpO9LfgCAqQ+vWrRMAxKlTp8SNGzeEubm5GDNmjFTfsmVLUatWLenxrVu3BACxbt26PH0BENOmTZMeT5s2TQAQw4cPl8qysrJEpUqVhImJiZg7d65U/ujRI6FSqYS/v79U9t///leYmpqKI0eOGC1nxYoVAoA4evSo0bJNTU3FxYsXjdp27dpVKBQKcePGDanszp07wtbWVrRo0aLQbbNjxw4BQMyfP99o/M2bN8+zDdq2bStq164t0tPTpTKDwSCaNGki3n777UKXk7NN7e3tRUpKilQeEhIiAIi6deuK58+fS+V9+/YVCoXCaFkvb/scVapUMdqms2bNEtbW1uLq1atG7SZNmiTMzMxEfHy8EEKITz75RKjVapGVlVXguLds2SIAiAMHDuS7XAAiIiIiT93Tp0/zlOl0OlG1alXp8fbt26XXZXHlLHvbtm1SWWpqqnBychLvvvuuVBYUFCQAGL2+Hj9+LNzc3ISrq6vIzs4WQghx4MABAUBUrVo137G/bP/+/QKA0fsoh8FgMBpn7ucmPT1dWmaOW7duCaVSKWbOnCmVdenSxeg9mZ+AgADh5OQkHjx4YFTep08fodFoirQe9PfAwxn0xqhatSoGDBiAVatW4e7duyXW79ChQ6X/m5mZoWHDhhBCICAgQCq3s7NDjRo1cPPmTalsy5Yt8PDwQM2aNfHgwQNpatOmDQDgwIEDRstp2bIlPD09pcfZ2dnYs2cPunbtiqpVq0rlTk5O+PDDD/Hrr78Wukv6l19+gbm5OUaOHGk0/tGjRxu1S05Oxv79+9GrVy88fvxYGufDhw+h0+lw7dq1fK98eVnPnj2h0Wikxzl7Sfr37w9zc3Oj8szMzCL1+bItW7agefPmKFeunNE29fHxQXZ2Ng4fPgzgxfPx5MkTREVFFXsZOdzc3KDT6fKUq1Qq6f+pqal48OABWrZsiZs3byI1NVVaPgCEhYXh+fPnxV62s7Oz0Z4EtVqNgQMH4uzZs0hMTATw4vlt1KgRmjVrJrWzsbHB8OHDcfv2bVy6dMmoT39/f6OxF2Tbtm0wMTHBtGnT8tSZmJgUOJ9SqYSp6YuvhOzsbDx8+BA2NjaoUaMGzpw5I7Wzs7PDH3/8gVOnTuXbjxAC27ZtQ+fOnSGEMHqedTodUlNTjfqjvzeGCHqjTJ48GVlZWcW+UqMwlStXNnqs0WhgaWmZ574SGo0Gjx49kh5fu3YNFy9ehL29vdFUvXp1AC92eefm5uZm9Pj+/ft4+vSptBs9Nw8PDxgMBiQkJBQ47t9//x1OTk6wsbExKn+5v+vXr0MIgSlTpuQZa84XyctjzU9+2wkAXFxc8i3Pva2K6tq1a4iIiMgzTh8fH6Nxfvzxx6hevTo6duyISpUqYciQIdI5JkX18vOR4+jRo/Dx8YG1tTXs7Oxgb2+Pzz77DACkENGyZUv4+flhxowZqFixIrp06YJ169blORemIO7u7nm+sHNeNzlXk/z+++8FvjZy6ouyPi+7ceMGnJ2dUb58+SK1z2EwGLBo0SK8/fbbUCqVqFixIuzt7XH+/HlpuwDAxIkTYWNjg0aNGuHtt99GYGAgjh49KtXfv38fKSkpWLVqVZ7nefDgwQCK9nqkvweeE0FvlKpVq6J///5YtWoVJk2alKe+oF9S2dnZBfaZ39UbBV3RIYSQ/m8wGFC7dm18/fXX+bZ9+cu1KL8SS0POCYnBwcH5/vIGXnypvUpB26Qo26ogLz8vBoMB7dq1w4QJE/Jtn/NF6+DggHPnziEyMhK7d+/G7t27sW7dOgwcOBDr169/5XKB/J+PGzduoG3btqhZsya+/vpruLi4QKFQ4JdffsGiRYukbWliYoKtW7fi+PHj2LVrFyIjIzFkyBAsXLgQx48fzxPs/gql/fqaPXs2pkyZgiFDhmDWrFkoX748TE1NERQUZHTSq4eHB+Li4hAWFoaIiAhs27YNy5Ytw9SpUzFjxgypbf/+/fM9fwcA6tSpU6rrQn8dhgh640yePBk//PCDdEJdbuXKlQOAPFcovPyrrSRUq1YNv/32G9q2bVvobuCC2Nvbw8rKCnFxcXnqrly5AlNT0zxBJLcqVapg3759SEtLM/rSerm/nEMlFhYW0i/6v1q5cuXyPCeZmZl5DktVq1YNaWlpRRqnQqFA586d0blzZxgMBnz88cdYuXIlpkyZku8v/aLYtWsXMjIysHPnTqM9Ly8fmsrh5eUFLy8vfPnll9i4cSP69euHTZs2GR0iy0/O3qHcY7x69SqAF1dvAC+e34JeGzn1clSrVg2RkZFITk4u1t6IrVu3onXr1vj++++NylNSUvLstbO2tkbv3r3Ru3dvZGZmonv37vjyyy8REhICe3t72NraIjs7u8xej/TX4eEMeuNUq1YN/fv3x8qVK6XjxznUajUqVqwoHTvPsWzZshIfR69evfDnn39i9erVeeqePXuGJ0+eFDq/mZkZ2rdvj59//tnohkhJSUnYuHEjmjVrBrVaXeD877//PrKysowuP8zOzsa3335r1M7BwQGtWrXCypUr8z2X5P79+4WOsyRUq1Ytz3OyatWqPHsievXqhejoaERGRubpIyUlBVlZWQCAhw8fGtWZmppKv15zDilYW1tL8xVVzl6V3HtRUlNTsW7dOqN2jx49yrOnpV69ekbLL8ydO3ewfft26bFer8d//vMf1KtXD1qtFsCL5/fkyZOIjo6W2j158gSrVq2Cq6ur0fk1xeHn5wchBGbMmJGnrrC9R2ZmZnnqt2zZkufcl5efG4VCAU9PTwgh8Pz5c5iZmcHPzw/btm3DhQsX8iznr3g90l+HeyLojfT555/jv//9L+Li4lCrVi2juqFDh2Lu3LkYOnQoGjZsiMOHD0u/8krSgAEDsHnzZowYMQIHDhxA06ZNkZ2djStXrmDz5s3SPQgK88UXXyAqKgrNmjXDxx9/DHNzc6xcuRIZGRmYP39+ofN27twZTZs2xaRJk3D79m3pXgO5j0/nWLp0KZo1a4batWtj2LBhqFq1KpKSkhAdHY0//vgj32v9S9LQoUMxYsQI+Pn5oV27dvjtt98QGRmZ5xfs+PHjsXPnTnTq1AmDBg1CgwYN8OTJE8TGxmLr1q24ffs2KlasiKFDhyI5ORlt2rRBpUqV8Pvvv+Pbb79FvXr1pHMG6tWrBzMzM8ybNw+pqalQKpXS/R8K0r59e2kPx0cffYS0tDSsXr0aDg4ORgFs/fr1WLZsGbp164Zq1arh8ePHWL16NdRqNd5///1Xbo/q1asjICAAp06dgqOjI9auXYukpCSjsDJp0iT873//Q8eOHTFmzBiUL18e69evx61bt7Bt2zbpJMfiat26NQYMGIAlS5bg2rVr6NChAwwGA44cOYLWrVtj1KhR+c7XqVMnzJw5E4MHD0aTJk0QGxuLDRs2GJ0UnLMNtVotmjZtCkdHR1y+fBnfffcdfH19YWtrCwCYO3cuDhw4gMaNG2PYsGHw9PREcnIyzpw5g7179+a5zwj9jZXJNSFE/1/uSzxf5u/vLwDkuZzs6dOnIiAgQGg0GmFrayt69eol7t27V+Alnvfv38/Tr7W1dZ7lvXw5qRBCZGZminnz5olatWoJpVIpypUrJxo0aCBmzJghUlNTpXYARGBgYL7reObMGaHT6YSNjY2wsrISrVu3FseOHXvlthFCiIcPH4oBAwYItVotNBqNGDBggDh79my+l7neuHFDDBw4UGi1WmFhYSHeeust0alTJ7F169ZCl5FzieeCBQuMynMuLdyyZYtReX7PWXZ2tpg4caKoWLGisLKyEjqdTly/fj3PZYRCvLiMMSQkRLi7uwuFQiEqVqwomjRpIr766iuRmZkphBBi69aton379sLBwUEoFApRuXJl8dFHH4m7d+8a9bV69WpRtWpVYWZmZnS5Z5UqVYSvr2++67tz505Rp04dYWlpKVxdXcW8efPE2rVrBQBx69YtIcSL56xv376icuXKQqlUCgcHB9GpUydx+vTpQrdl7mVHRkaKOnXqCKVSKWrWrJlnOwrx4jnr0aOHsLOzE5aWlqJRo0YiLCysSM9DYbKyssSCBQtEzZo1hUKhEPb29qJjx44iJibGaJwvX+L56aefCicnJ6FSqUTTpk1FdHS0aNmypWjZsqXUbuXKlaJFixaiQoUKQqlUimrVqonx48cbvR+EECIpKUkEBgYKFxcXYWFhIbRarWjbtq1YtWpVkdeD3nwmQhTh7CgiIioSV1dXvPPOOwgLCyvroRCVOp4TQURERLIwRBAREZEsDBFEREQkC8+JICIiIlm4J4KIiIhkYYggIiIiWf6xN5syGAy4c+cObG1tZd0el4iI6N9KCIHHjx/D2dm50Buf/WNDxJ07dwr9uwRERERUuISEBFSqVKnA+n9siMi5/WpCQkKhf5+AiIiIjOn1eri4uEjfpQX5x4aInEMYarWaIYKIiEiGV50OwBMriYiISBaGCCIiIpKFIYKIiIhkYYggIiIiWRgiiIiISBaGCCIiIpKFIYKIiIhkYYggIiIiWRgiiIiISBaGCCIiIpKFIYKIiIhkYYggIiIiWRgiiIiISBaGCCIiIpKFIYKIiIhkYYggIiIiWczLegB/N66Twst6CER/mdtzfct6CET0BuOeCCIiIpKFIYKIiIhkYYggIiIiWRgiiIiISBaGCCIiIpKFIYKIiIhkYYggIiIiWRgiiIiISBaGCCIiIpKFIYKIiIhkYYggIiIiWRgiiIiISBaGCCIiIpKFIYKIiIhkKVaIcHV1hYmJSZ4pMDAQAJCeno7AwEBUqFABNjY28PPzQ1JSklEf8fHx8PX1hZWVFRwcHDB+/HhkZWUZtTl48CDq168PpVIJd3d3hIaGvt5aEhERUYkrVog4deoU7t69K01RUVEAgJ49ewIAxo4di127dmHLli04dOgQ7ty5g+7du0vzZ2dnw9fXF5mZmTh27BjWr1+P0NBQTJ06VWpz69Yt+Pr6onXr1jh37hyCgoIwdOhQREZGlsT6EhERUQkxEUIIuTMHBQUhLCwM165dg16vh729PTZu3IgePXoAAK5cuQIPDw9ER0fDy8sLu3fvRqdOnXDnzh04OjoCAFasWIGJEyfi/v37UCgUmDhxIsLDw3HhwgVpOX369EFKSgoiIiKKPDa9Xg+NRoPU1FSo1Wq5q5iH66TwEuuL6E13e65vWQ+BiMpAUb9DZZ8TkZmZiR9++AFDhgyBiYkJYmJi8Pz5c/j4+EhtatasicqVKyM6OhoAEB0djdq1a0sBAgB0Oh30ej0uXrwotcndR06bnD4KkpGRAb1ebzQRERFR6ZEdInbs2IGUlBQMGjQIAJCYmAiFQgE7Ozujdo6OjkhMTJTa5A4QOfU5dYW10ev1ePbsWYHjmTNnDjQajTS5uLjIXTUiIiIqAtkh4vvvv0fHjh3h7OxckuORLSQkBKmpqdKUkJBQ1kMiIiL6RzOXM9Pvv/+OvXv34qeffpLKtFotMjMzkZKSYrQ3IikpCVqtVmpz8uRJo75yrt7I3eblKzqSkpKgVquhUqkKHJNSqYRSqZSzOkRERCSDrD0R69atg4ODA3x9/++kqwYNGsDCwgL79u2TyuLi4hAfHw9vb28AgLe3N2JjY3Hv3j2pTVRUFNRqNTw9PaU2ufvIaZPTBxEREb0Zih0iDAYD1q1bB39/f5ib/9+ODI1Gg4CAAIwbNw4HDhxATEwMBg8eDG9vb3h5eQEA2rdvD09PTwwYMAC//fYbIiMjMXnyZAQGBkp7EUaMGIGbN29iwoQJuHLlCpYtW4bNmzdj7NixJbTKREREVBKKfThj7969iI+Px5AhQ/LULVq0CKampvDz80NGRgZ0Oh2WLVsm1ZuZmSEsLAwjR46Et7c3rK2t4e/vj5kzZ0pt3NzcEB4ejrFjx2Lx4sWoVKkS1qxZA51OJ3MViYiIqDS81n0i3mS8TwTR6+N9Ioj+nUr9PhFERET078YQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIUO0T8+eef6N+/PypUqACVSoXatWvj9OnTUr0QAlOnToWTkxNUKhV8fHxw7do1oz6Sk5PRr18/qNVq2NnZISAgAGlpaUZtzp8/j+bNm8PS0hIuLi6YP3++zFUkIiKi0lCsEPHo0SM0bdoUFhYW2L17Ny5duoSFCxeiXLlyUpv58+djyZIlWLFiBU6cOAFra2vodDqkp6dLbfr164eLFy8iKioKYWFhOHz4MIYPHy7V6/V6tG/fHlWqVEFMTAwWLFiA6dOnY9WqVSWwykRERFQSTIQQoqiNJ02ahKNHj+LIkSP51gsh4OzsjE8//RTBwcEAgNTUVDg6OiI0NBR9+vTB5cuX4enpiVOnTqFhw4YAgIiICLz//vv4448/4OzsjOXLl+Pzzz9HYmIiFAqFtOwdO3bgypUrRRqrXq+HRqNBamoq1Gp1UVfxlVwnhZdYX0Rvuttzfct6CERUBor6HVqsPRE7d+5Ew4YN0bNnTzg4OODdd9/F6tWrpfpbt24hMTERPj4+UplGo0Hjxo0RHR0NAIiOjoadnZ0UIADAx8cHpqamOHHihNSmRYsWUoAAAJ1Oh7i4ODx69CjfsWVkZECv1xtNREREVHqKFSJu3ryJ5cuX4+2330ZkZCRGjhyJMWPGYP369QCAxMREAICjo6PRfI6OjlJdYmIiHBwcjOrNzc1Rvnx5ozb59ZF7GS+bM2cONBqNNLm4uBRn1YiIiKiYihUiDAYD6tevj9mzZ+Pdd9/F8OHDMWzYMKxYsaK0xldkISEhSE1NlaaEhISyHhIREdE/WrFChJOTEzw9PY3KPDw8EB8fDwDQarUAgKSkJKM2SUlJUp1Wq8W9e/eM6rOyspCcnGzUJr8+ci/jZUqlEmq12mgiIiKi0lOsENG0aVPExcUZlV29ehVVqlQBALi5uUGr1WLfvn1SvV6vx4kTJ+Dt7Q0A8Pb2RkpKCmJiYqQ2+/fvh8FgQOPGjaU2hw8fxvPnz6U2UVFRqFGjhtGVIERERFR2ihUixo4di+PHj2P27Nm4fv06Nm7ciFWrViEwMBAAYGJigqCgIHzxxRfYuXMnYmNjMXDgQDg7O6Nr164AXuy56NChA4YNG4aTJ0/i6NGjGDVqFPr06QNnZ2cAwIcffgiFQoGAgABcvHgRP/74IxYvXoxx48aV7NoTERGRbObFafzee+9h+/btCAkJwcyZM+Hm5oZvvvkG/fr1k9pMmDABT548wfDhw5GSkoJmzZohIiIClpaWUpsNGzZg1KhRaNu2LUxNTeHn54clS5ZI9RqNBnv27EFgYCAaNGiAihUrYurUqUb3kiAiIqKyVaz7RPyd8D4RRK+P94kg+ncqlftEEBEREeVgiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIlmKFiOnTp8PExMRoqlmzplSfnp6OwMBAVKhQATY2NvDz80NSUpJRH/Hx8fD19YWVlRUcHBwwfvx4ZGVlGbU5ePAg6tevD6VSCXd3d4SGhspfQyIiIioVxd4TUatWLdy9e1eafv31V6lu7Nix2LVrF7Zs2YJDhw7hzp076N69u1SfnZ0NX19fZGZm4tixY1i/fj1CQ0MxdepUqc2tW7fg6+uL1q1b49y5cwgKCsLQoUMRGRn5mqtKREREJcm82DOYm0Or1eYpT01Nxffff4+NGzeiTZs2AIB169bBw8MDx48fh5eXF/bs2YNLly5h7969cHR0RL169TBr1ixMnDgR06dPh0KhwIoVK+Dm5oaFCxcCADw8PPDrr79i0aJF0Ol0r7m6REREVFKKvSfi2rVrcHZ2RtWqVdGvXz/Ex8cDAGJiYvD8+XP4+PhIbWvWrInKlSsjOjoaABAdHY3atWvD0dFRaqPT6aDX63Hx4kWpTe4+ctrk9FGQjIwM6PV6o4mIiIhKT7FCROPGjREaGoqIiAgsX74ct27dQvPmzfH48WMkJiZCoVDAzs7OaB5HR0ckJiYCABITE40CRE59Tl1hbfR6PZ49e1bg2ObMmQONRiNNLi4uxVk1IiIiKqZiHc7o2LGj9P86deqgcePGqFKlCjZv3gyVSlXigyuOkJAQjBs3Tnqs1+sZJIiIiErRa13iaWdnh+rVq+P69evQarXIzMxESkqKUZukpCTpHAqtVpvnao2cx69qo1arCw0qSqUSarXaaCIiIqLS81ohIi0tDTdu3ICTkxMaNGgACwsL7Nu3T6qPi4tDfHw8vL29AQDe3t6IjY3FvXv3pDZRUVFQq9Xw9PSU2uTuI6dNTh9ERET0ZihWiAgODsahQ4dw+/ZtHDt2DN26dYOZmRn69u0LjUaDgIAAjBs3DgcOHEBMTAwGDx4Mb29veHl5AQDat28PT09PDBgwAL/99hsiIyMxefJkBAYGQqlUAgBGjBiBmzdvYsKECbhy5QqWLVuGzZs3Y+zYsSW/9kRERCRbsc6J+OOPP9C3b188fPgQ9vb2aNasGY4fPw57e3sAwKJFi2Bqago/Pz9kZGRAp9Nh2bJl0vxmZmYICwvDyJEj4e3tDWtra/j7+2PmzJlSGzc3N4SHh2Ps2LFYvHgxKlWqhDVr1vDyTiIiojeMiRBClPUgSoNer4dGo0FqamqJnh/hOim8xPoietPdnutb1kMgojJQ1O9Q/u0MIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZXitEzJ07FyYmJggKCpLK0tPTERgYiAoVKsDGxgZ+fn5ISkoymi8+Ph6+vr6wsrKCg4MDxo8fj6ysLKM2Bw8eRP369aFUKuHu7o7Q0NDXGSoRERGVMNkh4tSpU1i5ciXq1KljVD527Fjs2rULW7ZswaFDh3Dnzh10795dqs/Ozoavry8yMzNx7NgxrF+/HqGhoZg6darU5tatW/D19UXr1q1x7tw5BAUFYejQoYiMjJQ7XCIiIiphskJEWloa+vXrh9WrV6NcuXJSeWpqKr7//nt8/fXXaNOmDRo0aIB169bh2LFjOH78OABgz549uHTpEn744QfUq1cPHTt2xKxZs7B06VJkZmYCAFasWAE3NzcsXLgQHh4eGDVqFHr06IFFixaVwCoTERFRSZAVIgIDA+Hr6wsfHx+j8piYGDx//tyovGbNmqhcuTKio6MBANHR0ahduzYcHR2lNjqdDnq9HhcvXpTavNy3TqeT+shPRkYG9Hq90URERESlx7y4M2zatAlnzpzBqVOn8tQlJiZCoVDAzs7OqNzR0RGJiYlSm9wBIqc+p66wNnq9Hs+ePYNKpcqz7Dlz5mDGjBnFXR0iIiKSqVh7IhISEvDJJ59gw4YNsLS0LK0xyRISEoLU1FRpSkhIKOshERER/aMVK0TExMTg3r17qF+/PszNzWFubo5Dhw5hyZIlMDc3h6OjIzIzM5GSkmI0X1JSErRaLQBAq9XmuVoj5/Gr2qjV6nz3QgCAUqmEWq02moiIiKj0FCtEtG3bFrGxsTh37pw0NWzYEP369ZP+b2FhgX379knzxMXFIT4+Ht7e3gAAb29vxMbG4t69e1KbqKgoqNVqeHp6Sm1y95HTJqcPIiIiKnvFOifC1tYW77zzjlGZtbU1KlSoIJUHBARg3LhxKF++PNRqNUaPHg1vb294eXkBANq3bw9PT08MGDAA8+fPR2JiIiZPnozAwEAolUoAwIgRI/Ddd99hwoQJGDJkCPbv34/NmzcjPDy8JNaZiIiISkCxT6x8lUWLFsHU1BR+fn7IyMiATqfDsmXLpHozMzOEhYVh5MiR8Pb2hrW1Nfz9/TFz5kypjZubG8LDwzF27FgsXrwYlSpVwpo1a6DT6Up6uERERCSTiRBClPUgSoNer4dGo0FqamqJnh/hOol7Q+jf4/Zc37IeAhGVgaJ+h/JvZxAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkS7FCxPLly1GnTh2o1Wqo1Wp4e3tj9+7dUn16ejoCAwNRoUIF2NjYwM/PD0lJSUZ9xMfHw9fXF1ZWVnBwcMD48eORlZVl1ObgwYOoX78+lEol3N3dERoaKn8NiYiIqFQUK0RUqlQJc+fORUxMDE6fPo02bdqgS5cuuHjxIgBg7Nix2LVrF7Zs2YJDhw7hzp076N69uzR/dnY2fH19kZmZiWPHjmH9+vUIDQ3F1KlTpTa3bt2Cr68vWrdujXPnziEoKAhDhw5FZGRkCa0yERERlQQTIYR4nQ7Kly+PBQsWoEePHrC3t8fGjRvRo0cPAMCVK1fg4eGB6OhoeHl5Yffu3ejUqRPu3LkDR0dHAMCKFSswceJE3L9/HwqFAhMnTkR4eDguXLggLaNPnz5ISUlBREREkcel1+uh0WiQmpoKtVr9OqtoxHVSeIn1RfSmuz3Xt6yHQERloKjfobLPicjOzsamTZvw5MkTeHt7IyYmBs+fP4ePj4/UpmbNmqhcuTKio6MBANHR0ahdu7YUIABAp9NBr9dLezOio6ON+shpk9NHQTIyMqDX640mIiIiKj3FDhGxsbGwsbGBUqnEiBEjsH37dnh6eiIxMREKhQJ2dnZG7R0dHZGYmAgASExMNAoQOfU5dYW10ev1ePbsWYHjmjNnDjQajTS5uLgUd9WIiIioGIodImrUqIFz587hxIkTGDlyJPz9/XHp0qXSGFuxhISEIDU1VZoSEhLKekhERET/aObFnUGhUMDd3R0A0KBBA5w6dQqLFy9G7969kZmZiZSUFKO9EUlJSdBqtQAArVaLkydPGvWXc/VG7jYvX9GRlJQEtVoNlUpV4LiUSiWUSmVxV4eIiIhkeu37RBgMBmRkZKBBgwawsLDAvn37pLq4uDjEx8fD29sbAODt7Y3Y2Fjcu3dPahMVFQW1Wg1PT0+pTe4+ctrk9EFERERvhmLtiQgJCUHHjh1RuXJlPH78GBs3bsTBgwcRGRkJjUaDgIAAjBs3DuXLl4darcbo0aPh7e0NLy8vAED79u3h6emJAQMGYP78+UhMTMTkyZMRGBgo7UUYMWIEvvvuO0yYMAFDhgzB/v37sXnzZoSH86oIIiKiN0mxQsS9e/cwcOBA3L17FxqNBnXq1EFkZCTatWsHAFi0aBFMTU3h5+eHjIwM6HQ6LFu2TJrfzMwMYWFhGDlyJLy9vWFtbQ1/f3/MnDlTauPm5obw8HCMHTsWixcvRqVKlbBmzRrodLoSWmUiIiIqCa99n4g3Fe8TQfT6eJ8Ion+nUr9PBBEREf27MUQQERGRLAwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJAtDBBEREcnCEEFERESyMEQQERGRLAwRREREJEuxQsScOXPw3nvvwdbWFg4ODujatSvi4uKM2qSnpyMwMBAVKlSAjY0N/Pz8kJSUZNQmPj4evr6+sLKygoODA8aPH4+srCyjNgcPHkT9+vWhVCrh7u6O0NBQeWtIREREpaJYIeLQoUMIDAzE8ePHERUVhefPn6N9+/Z48uSJ1Gbs2LHYtWsXtmzZgkOHDuHOnTvo3r27VJ+dnQ1fX19kZmbi2LFjWL9+PUJDQzF16lSpza1bt+Dr64vWrVvj3LlzCAoKwtChQxEZGVkCq0xEREQlwUQIIeTOfP/+fTg4OODQoUNo0aIFUlNTYW9vj40bN6JHjx4AgCtXrsDDwwPR0dHw8vLC7t270alTJ9y5cweOjo4AgBUrVmDixIm4f/8+FAoFJk6ciPDwcFy4cEFaVp8+fZCSkoKIiIgijU2v10Oj0SA1NRVqtVruKubhOim8xPoietPdnutb1kMgojJQ1O/Q1zonIjU1FQBQvnx5AEBMTAyeP38OHx8fqU3NmjVRuXJlREdHAwCio6NRu3ZtKUAAgE6ng16vx8WLF6U2ufvIaZPTR34yMjKg1+uNJiIiIio9skOEwWBAUFAQmjZtinfeeQcAkJiYCIVCATs7O6O2jo6OSExMlNrkDhA59Tl1hbXR6/V49uxZvuOZM2cONBqNNLm4uMhdNSIiIioC2SEiMDAQFy5cwKZNm0pyPLKFhIQgNTVVmhISEsp6SERERP9o5nJmGjVqFMLCwnD48GFUqlRJKtdqtcjMzERKSorR3oikpCRotVqpzcmTJ436y7l6I3ebl6/oSEpKglqthkqlyndMSqUSSqVSzuoQERGRDMXaEyGEwKhRo7B9+3bs378fbm5uRvUNGjSAhYUF9u3bJ5XFxcUhPj4e3t7eAABvb2/Exsbi3r17UpuoqCio1Wp4enpKbXL3kdMmpw8iIiIqe8XaExEYGIiNGzfi559/hq2trXQOg0ajgUqlgkajQUBAAMaNG4fy5ctDrVZj9OjR8Pb2hpeXFwCgffv28PT0xIABAzB//nwkJiZi8uTJCAwMlPYkjBgxAt999x0mTJiAIUOGYP/+/di8eTPCw3llBBER0ZuiWHsili9fjtTUVLRq1QpOTk7S9OOPP0ptFi1ahE6dOsHPzw8tWrSAVqvFTz/9JNWbmZkhLCwMZmZm8Pb2Rv/+/TFw4EDMnDlTauPm5obw8HBERUWhbt26WLhwIdasWQOdTlcCq0xEREQl4bXuE/Em430iiF4f7xNB9O/0l9wngoiIiP69GCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikoUhgoiIiGRhiCAiIiJZGCKIiIhIFoYIIiIikqXYIeLw4cPo3LkznJ2dYWJigh07dhjVCyEwdepUODk5QaVSwcfHB9euXTNqk5ycjH79+kGtVsPOzg4BAQFIS0szanP+/Hk0b94clpaWcHFxwfz584u/dkRERFRqih0injx5grp162Lp0qX51s+fPx9LlizBihUrcOLECVhbW0On0yE9PV1q069fP1y8eBFRUVEICwvD4cOHMXz4cKler9ejffv2qFKlCmJiYrBgwQJMnz4dq1atkrGKREREVBpMhBBC9swmJti+fTu6du0K4MVeCGdnZ3z66acIDg4GAKSmpsLR0RGhoaHo06cPLl++DE9PT5w6dQoNGzYEAEREROD999/HH3/8AWdnZyxfvhyff/45EhMToVAoAACTJk3Cjh07cOXKlSKNTa/XQ6PRIDU1FWq1Wu4q5uE6KbzE+iJ6092e61vWQyCiMlDU79ASPSfi1q1bSExMhI+Pj1Sm0WjQuHFjREdHAwCio6NhZ2cnBQgA8PHxgampKU6cOCG1adGihRQgAECn0yEuLg6PHj3Kd9kZGRnQ6/VGExEREZWeEg0RiYmJAABHR0ejckdHR6kuMTERDg4ORvXm5uYoX768UZv8+si9jJfNmTMHGo1GmlxcXF5/hYiIiKhA/5irM0JCQpCamipNCQkJZT0kIiKif7QSDRFarRYAkJSUZFSelJQk1Wm1Wty7d8+oPisrC8nJyUZt8usj9zJeplQqoVarjSYiIiIqPSUaItzc3KDVarFv3z6pTK/X48SJE/D29gYAeHt7IyUlBTExMVKb/fv3w2AwoHHjxlKbw4cP4/nz51KbqKgo1KhRA+XKlSvJIRMREZFMxQ4RaWlpOHfuHM6dOwfgxcmU586dQ3x8PExMTBAUFIQvvvgCO3fuRGxsLAYOHAhnZ2fpCg4PDw906NABw4YNw8mTJ3H06FGMGjUKffr0gbOzMwDgww8/hEKhQEBAAC5evIgff/wRixcvxrhx40psxYmIiOj1mBd3htOnT6N169bS45wvdn9/f4SGhmLChAl48uQJhg8fjpSUFDRr1gwRERGwtLSU5tmwYQNGjRqFtm3bwtTUFH5+fliyZIlUr9FosGfPHgQGBqJBgwaoWLEipk6danQvCSIiIipbr3WfiDcZ7xNB9Pp4nwiif6cyuU8EERER/XswRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQki3lZD4CIqDS4Tgov6yEQ/WVuz/Utk+VyTwQRERHJwhBBREREsjBEEBERkSwMEURERCQLQwQRERHJwhBBREREsjBEEBERkSwMEURERCQLQwQRERHJwhBBREREsjBEEBERkSwMEURERCQLQwQRERHJwhBBREREsjBEEBERkSwMEURERCQLQwQRERHJwhBBREREsrzRIWLp0qVwdXWFpaUlGjdujJMnT5b1kIiIiOj/e2NDxI8//ohx48Zh2rRpOHPmDOrWrQudTod79+6V9dCIiIgIb3CI+PrrrzFs2DAMHjwYnp6eWLFiBaysrLB27dqyHhoREREBMC/rAeQnMzMTMTExCAkJkcpMTU3h4+OD6OjofOfJyMhARkaG9Dg1NRUAoNfrS3RshoynJdof0ZuspN8/fyW+V+nfpKTfqzn9CSEKbfdGhogHDx4gOzsbjo6ORuWOjo64cuVKvvPMmTMHM2bMyFPu4uJSKmMk+jfQfFPWIyCioiit9+rjx4+h0WgKrH8jQ4QcISEhGDdunPTYYDAgOTkZFSpUgImJSRmOjF6XXq+Hi4sLEhISoFary3o4RFQAvlf/OYQQePz4MZydnQtt90aGiIoVK8LMzAxJSUlG5UlJSdBqtfnOo1QqoVQqjcrs7OxKa4hUBtRqNT+YiP4G+F79ZyhsD0SON/LESoVCgQYNGmDfvn1SmcFgwL59++Dt7V2GIyMiIqIcb+SeCAAYN24c/P390bBhQzRq1AjffPMNnjx5gsGDB5f10IiIiAhvcIjo3bs37t+/j6lTpyIxMRH16tVDREREnpMt6Z9PqVRi2rRpeQ5XEdGbhe/Vfx8T8arrN4iIiIjy8UaeE0FERERvPoYIIiIikoUhgoiIiGRhiCAiIiJZGCKo1JiYmGDHjh1/ybKmT5+OevXq/SXLKkhoaKjRDc7+qjFNmTIFw4cPL3L7zMxMuLq64vTp06U4KipLBw8ehImJCVJSUv6S5bVq1QpBQUF/ybIKMmjQIHTt2lV6/FeNqUWLFti4cWOR2z948AAODg74448/SnFUfx2GiBIyaNAgmJiYYO7cuUblO3bseO3bboeGhsLExAQmJiYwNTVFpUqVMHjwYP5Z9BKW8xyamJhAoVDA3d0dM2fORFZWlqz+goODjW6YVhoSExOxePFifP7550blS5cuhaurKywtLdG4cWOcPHlSqlMoFAgODsbEiRNLdWz/FCX9uqD8ubq6StvZ2toa9evXx5YtW2T399NPP2HWrFklOMK8du7ciaSkJPTp00cqW7VqFVq1agW1Wp1vkKtYsSIGDhyIadOmlerY/ioMESXI0tIS8+bNw6NHj0q8b7Vajbt37+KPP/7A6tWrsXv3bgwYMKDEl/MmyczM/MuX2aFDB9y9exfXrl3Dp59+iunTp2PBggWy+rKxsUGFChVKeITG1qxZgyZNmqBKlSpS2Y8//ohx48Zh2rRpOHPmDOrWrQudTmcUOvv164dff/0VFy9eLNXx/VOU5Ovi76Is3n8zZ87E3bt3cfbsWbz33nvo3bs3jh07Jquv8uXLw9bWtoRHaGzJkiUYPHgwTE3/76v06dOn6NChAz777LMC5xs8eDA2bNiA5OTkUh3fX4EhogT5+PhAq9Vizpw5hbbbtm0batWqBaVSCVdXVyxcuPCVfZuYmECr1cLZ2RkdO3bEmDFjsHfvXjx79gwGgwEzZ85EpUqVoFQqpRtz5cjMzMSoUaPg5OQES0tLVKlSxWiMKSkpGDp0KOzt7aFWq9GmTRv89ttvRsv/+eefUb9+fVhaWqJq1aqYMWOG0S+xa9euoUWLFrC0tISnpyeioqLyrENsbCzatGkDlUqFChUqYPjw4UhLS5Pqc3ZHfvnll3B2dkaNGjUK3B5z586Fo6MjbG1tERAQgPT09Dxt1qxZAw8PD1haWqJmzZpYtmzZK7ezUqmEVqtFlSpVMHLkSPj4+GDnzp0AgEePHmHgwIEoV64crKys0LFjR1y7dq3Avl4+nJHzKyv35OrqCgDIzs5GQEAA3NzcoFKpUKNGDSxevPiV4920aRM6d+5sVPb1119j2LBhGDx4MDw9PbFixQpYWVlh7dq1Upty5cqhadOm2LRp0yuXQa/3uvj999/RuXNnlCtXDtbW1qhVqxZ++eUXqf7ChQvo2LEjbGxs4OjoiAEDBuDBgwdSvcFgwJw5c6TXRt26dbF161aj8f3yyy+oXr06VCoVWrdujdu3b+dZh1d97ri6umLWrFkYOHAg1Gp1gYfInjx5goEDB8LGxgZOTk75fn5lZGQgODgYb731FqytrdG4cWMcPHjwldvZ1tYWWq0W1atXx9KlS6FSqbBr1y4Ar/78eFnuwxk5h3dengYNGgQAuHHjBrp06QJHR0fY2Njgvffew969ewsd6/3797F///4877+goCBMmjQJXl5eBc5bq1YtODs7Y/v27a/cJm86hogSZGZmhtmzZ+Pbb78t8HhXTEwMevXqhT59+iA2NhbTp0/HlClTEBoaWqxlqVQqGAwGZGVlYfHixVi4cCG++uornD9/HjqdDh988IH0QbZkyRLs3LkTmzdvRlxcHDZs2CB9eQFAz549ce/ePezevRsxMTGoX78+2rZtK6XkI0eOYODAgfjkk09w6dIlrFy5EqGhofjyyy8BvPiQ6969OxQKBU6cOIEVK1bk2VX+5MkT6HQ6lCtXDqdOncKWLVuwd+9ejBo1yqjdvn37EBcXh6ioKISFheW77ps3b8b06dMxe/ZsnD59Gk5OTnkCwoYNGzB16lR8+eWXuHz5MmbPno0pU6Zg/fr1xd7OOb/IBg0ahNOnT2Pnzp2Ijo6GEALvv/8+nj9/XqS+7t69K03Xr1+Hu7s7WrRoAeDFNqxUqRK2bNmCS5cuYerUqfjss8+wefPmAvtLTk7GpUuX0LBhQ6ksMzMTMTEx8PHxkcpMTU3h4+OD6Ohoo/kbNWqEI0eOFHlb0P8pzusiMDAQGRkZOHz4MGJjYzFv3jzY2NgAeBHg27Rpg3fffRenT59GREQEkpKS0KtXL2lZc+bMwX/+8x+sWLECFy9exNixY9G/f38cOnQIAJCQkIDu3bujc+fOOHfuHIYOHYpJkyYZjbeonztfffUV6tati7Nnz2LKlCn5rvv48eNx6NAh/Pzzz9izZw8OHjyIM2fOGLUZNWoUoqOjsWnTJpw/fx49e/ZEhw4dCg3dLzM3N4eFhQUyMzOL/PlRkCZNmhi9//bv3w9LS0vp/ZeWlob3338f+/btw9mzZ9GhQwd07twZ8fHxBfb566+/wsrKCh4eHkVep9z+Me8/QSXC399fdOnSRQghhJeXlxgyZIgQQojt27eL3Jv5ww8/FO3atTOad/z48cLT07PAvtetWyc0Go30+OrVq6J69eqiYcOGQgghnJ2dxZdffmk0z3vvvSc+/vhjIYQQo0ePFm3atBEGgyFP30eOHBFqtVqkp6cblVerVk2sXLlSCCFE27ZtxezZs43q//vf/wonJychhBCRkZHC3Nxc/Pnnn1L97t27BQCxfft2IYQQq1atEuXKlRNpaWlSm/DwcGFqaioSExOFEC+2oaOjo8jIyChwWwghhLe3t7RuORo3bizq1q1rNP6NGzcatZk1a5bw9vYusN/cz6HBYBBRUVFCqVSK4OBgcfXqVQFAHD16VGr/4MEDoVKpxObNm4UQeZ+nadOmGY0ph8FgEN26dRMNGjQQT58+LXA8gYGBws/Pr8D6s2fPCgAiPj5eKvvzzz8FAHHs2DGjtuPHjxeNGjUyKlu8eLFwdXUtsH964XVfF7Vr1xbTp0/Pt+9Zs2aJ9u3bG5UlJCQIACIuLk6kp6cLKyurPM9nQECA6Nu3rxBCiJCQkDyfHxMnThQAxKNHj4QQRfvcqVKliujatWuh2+Lx48dCoVBI6yaEEA8fPhQqlUp88sknQgghfv/9d2FmZmb0eSDEi8+RkJCQAvuuUqWKWLRokRBCiIyMDDF79mwBQISFhRX58yPneRJCiJYtW0pjyu3BgweiatWqeT5DXlarVi3x7bffFli/aNEiUbVq1QLrDxw4YPQcvGzs2LGiVatWhY7h7+CN/dsZf2fz5s1DmzZtEBwcnKfu8uXL6NKli1FZ06ZN8c033yA7OxtmZmb59pmamgobGxsYDAakp6ejWbNmWLNmDfR6Pe7cuYOmTZvm6TPnkMSgQYPQrl071KhRAx06dECnTp3Qvn17AMBvv/2GtLS0PMfunz17hhs3bkhtjh49Ku15AF7sfk9PT8fTp09x+fJluLi4GP3d+Zf/2urly5dRt25dWFtbG43RYDAgLi5O+psotWvXhkKhyHcb5O5rxIgRRmXe3t44cOAAgBd7PW7cuIGAgAAMGzZMapOVlfXKP20bFhYGGxsbPH/+HAaDAR9++CGmT5+Offv2wdzcHI0bN5baVqhQATVq1MDly5cL7fNln332GaKjo3H69GmoVCqpfOnSpVi7di3i4+Px7NkzZGZmFnp1x7NnzwC8OBdHDpVKhadPn8qa99/mdV4XY8aMwciRI7Fnzx74+PjAz88PderUAfDivXXgwAFpz0RuN27cwPPnz/H06VO0a9fOqC4zMxPvvvsugBfvh9zLB/J//xXlcyf3Xq383LhxA5mZmUbLK1++vNGhx9jYWGRnZ6N69epG82ZkZLzyHKGJEydi8uTJSE9Ph42NDebOnQtfX1+MGzeuSJ8fr/L8+XP4+fmhSpUqRocL09LSMH36dISHh+Pu3bvIysrCs2fPCt0T8ezZM9nvPeCf8/5jiCgFLVq0gE6nQ0hIiHTM7XXZ2trizJkzMDU1hZOTk/Tlo9frXzlv/fr1cevWLezevRt79+5Fr1694OPjg61btyItLQ1OTk75Hq/MuVwxLS0NM2bMQPfu3fO0eZ03UX5yf0jIlXOcdPXq1Xk+XAsKaTlat26N5cuXQ6FQwNnZGebmJfsW+eGHH7Bo0SIcPHgQb731llS+adMmBAcHY+HChfD29oatrS0WLFiAEydOFNhXxYoVAbw4Jm9vby+VmZmZISkpyahtUlIStFqtUVlycrI0HxXudV4XQ4cOhU6nQ3h4OPbs2YM5c+Zg4cKFGD16NNLS0tC5c2fMmzcvz3xOTk64cOECACA8PNzo9QKgVP7IVUm9/8zMzBATE5Pn/ZZfWMpt/PjxGDRokHR+yOte2faykSNHIiEhASdPnjR6DoODgxEVFYWvvvoK7u7uUKlU6NGjR6Enl1asWPG1TqL/p7z/GCJKydy5c1GvXr08Jwd6eHjg6NGjRmVHjx5F9erVC/2CMzU1hbu7e55ytVoNZ2dnHD16FC1btjTqs1GjRkbtevfujd69e6NHjx7o0KEDkpOTUb9+fSQmJsLc3NzoPInc6tevj7i4uHyXn7NOCQkJuHv3LpycnAAAx48fz9MmNDQUT548kT6ojh49ClNT00JPoCxoeSdOnMDAgQOlstzLc3R0hLOzM27evIl+/foVq29ra+t819PDwwNZWVk4ceIEmjRpAgB4+PAh4uLi4OnpWaS+o6OjMXToUKxcuTLPSVdHjx5FkyZN8PHHH0tlOXuCClKtWjWo1WpcunRJ+tWnUCjQoEED7Nu3T7pm3mAwYN++fXmOH1+4cEH6NUuFe93XhYuLC0aMGIERI0YgJCQEq1evxujRo1G/fn1s27YNrq6u+QYTT09PKJVKxMfHG72/Xx5DzkmeOfJ7/8n53HlZtWrVYGFhgRMnTqBy5coAXoTYq1evSuN79913kZ2djXv37qF58+ZF7ht48cVc0HZ+3c+Pr7/+Gps3b8axY8fy7BE5evQoBg0ahG7dugF4EYTyOzk1t3fffReJiYl49OgRypUrV6Qx5HbhwgW0atWq2PO9ccr6eMo/xcvH44QQYsCAAcLS0tLonIiYmBhhamoqZs6cKeLi4kRoaKhQqVRi3bp1Bfb98rH2ly1atEio1WqxadMmceXKFTFx4kRhYWEhrl69KoQQYuHChWLjxo3i8uXLIi4uTgQEBAitViuys7OFwWAQzZo1E3Xr1hWRkZHi1q1b4ujRo+Kzzz4Tp06dEkIIERERIczNzcX06dPFhQsXxKVLl8T//vc/8fnnnwshhMjOzhaenp6iXbt24ty5c+Lw4cOiQYMGRudEPHnyRDg5OQk/Pz8RGxsr9u/fL6pWrSr8/f0L3Yb52bRpk7C0tBRr164VcXFxYurUqcLW1tbo/IPVq1cLlUolFi9eLOLi4sT58+fF2rVrxcKFCwvs91XL79Kli/D09BRHjhwR586dEx06dBDu7u4iMzNTCFH4ORF3794Vjo6Owt/fX9y9e1ea7t27J4R4cX6CWq0WERERIi4uTkyePFmo1ep8z6nIrXv37uLTTz/Ns32USqUIDQ0Vly5dEsOHDxd2dnbSseMcVapUEf/5z38K7Z9e/3XxySefiIiICHHz5k0RExMjGjduLHr16iWEeHEOi729vejRo4c4efKkuH79uoiIiBCDBg0SWVlZQgghPv/8c1GhQgURGhoqrl+/LmJiYsSSJUtEaGioEOLFOQgKhUIEBweLK1euiA0bNgitVmt0PL4onzu5z0kozIgRI0SVKlXEvn37RGxsrPjggw+EjY2N0fkH/fr1E66urmLbtm3i5s2b4sSJE2L27NkiLCyswH4LW76cz4/c50RERUUJMzMzsWLFCqP3X0pKihBCiG7duol69eqJs2fPinPnzonOnTsLW1vbfM+pyJGVlSXs7e3Frl27jMrv3r0rzp49K1avXi0AiMOHD4uzZ8+Khw8fGq2PSqUShw8fLrD/vwuGiBKS3wfNrVu3hEKhEC9nta1btwpPT09hYWEhKleuLBYsWFBo368KEdnZ2WL69OnirbfeEhYWFqJu3bpi9+7dUv2qVatEvXr1hLW1tVCr1aJt27bizJkzUr1erxejR48Wzs7OwsLCQri4uIh+/foZnbAXEREhmjRpIlQqlVCr1aJRo0Zi1apVUn1cXJxo1qyZUCgUonr16iIiIsIoRAghxPnz50Xr1q2FpaWlKF++vBg2bJh4/PhxoduwIF9++aWoWLGisLGxEf7+/mLChAl5vnA3bNgg6tWrJxQKhShXrpxo0aKF+Omnnwrs81XLT05OFgMGDBAajUaoVCqh0+mkoCZE4SEi5ySrl6cqVaoIIYRIT08XgwYNEhqNRtjZ2YmRI0eKSZMmvTJE/PLLL+Ktt94S2dnZRuXffvutqFy5slAoFKJRo0bi+PHjRvXHjh0TdnZ2hZ7YSS+87uti1KhRolq1akKpVAp7e3sxYMAA8eDBA6n+6tWrolu3bsLOzk6oVCpRs2ZNERQUJJ0IbTAYxDfffCNq1KghLCwshL29vdDpdOLQoUNSH7t27RLu7u5CqVSK5s2bi7Vr1+Y5qe9VnztFDRGPHz8W/fv3F1ZWVsLR0VHMnz8/z0mMmZmZYurUqcLV1VVYWFgIJycn0a1bN3H+/PkC+33V8ov7+ZF7TNOmTcv3/ZcTQm7duiVat24tVCqVcHFxEd99912BJ2bmNmHCBNGnTx+jsoKWlTuwbdy4UdSoUaPQvv8uTIQQ4q/c80FEJUcIgcaNG2Ps2LHo27dvkefr3bs36tatW+gNcYiocImJiahVqxbOnDljdMO3V/Hy8sKYMWPw4YcfluLo/hq8TwTR35iJiQlWrVpVrFswZ2Zmonbt2hg7dmwpjozon0+r1eL7778v9CqOlz148ADdu3cvVuh/k3FPBBEREcnCPRFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQkC0MEERERycIQQURERLIwRBAREZEsDBFEREQky/8DHYvVdQqXehAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muestras totales en entrenamiento:  7858\n",
            "--- Clase 0 ---\n",
            "Muestras en train:  7384\n",
            "Porcentaje en train:  93.97%\n",
            "--- Clase 1 ---\n",
            "Muestras en train:  474\n",
            "Porcentaje en train:  6.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analizando los datos vemos en la gráfica de barras del número de muestras por clases que las clases estan desbalanceadas en cuanto al número de datos por clase.  En una clase hay más del 90 % de los datos y en la otra el resto que es menos del 10% del total.  \n",
        "Debido a este desbalanceo, será necesario utilizar métricas de error para evaluar los resultados de los modelos distintas de la métrica de accuracy, ya que al tener un desbalanceo de mas del 90%, un clasificador que clasifique todas las muestras como la clase mayoritaria acertaría en todas las muestras de esa clase, y al representar más del 90% del conjunto de datos, obtendría un accuracy igual al porcentaje de muestras de esa clase (mas del 90%) aunque el clasificador no haya sido entrenado y falle en todas las muestras de la clase minoritaria."
      ],
      "metadata": {
        "id": "ZgJ87l8ZPZKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Datos faltantes:**"
      ],
      "metadata": {
        "id": "7EV0gMEoRvjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ver si faltan datos en nuestro conjunto de datos, vamos a utilizar la función `isnull()` de la librería pandas para contar el número de datos que faltan en el conjunto. Esta función detecta si algún valor en el conjunto de datos es del tipo no numéricos o de valor nulo y devuelve una matriz de la misma forma que el conjunto de datos que recibe como parámetro, en el que cada posición devuelve verdadero si falta el dato o falso si no falta el dato:"
      ],
      "metadata": {
        "id": "7-6K0zLHSiDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfTrainX = pd.DataFrame(trainX) #crear dataframe para utilizar las funciones de al libreria de Pandas\n",
        "num_missing = np.sum(dfTrainX.isnull().values)\n",
        "print(\"Número de datos faltantes: \", num_missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7vAvxvnShiA",
        "outputId": "4420b569-c18b-43f6-bb36-8d55c63e7d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de datos faltantes:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar no existen datos faltantes en nuestro conjunto de datos y por tanto no hay que realizar ninguna acción al respecto ya que no tenemos ningún problema de datos faltantes."
      ],
      "metadata": {
        "id": "2qaSIz4NToCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Codificación de los datos**"
      ],
      "metadata": {
        "id": "_eeeY_9vVCsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para las variables categóricas que no tienen un orden de jerarquía entre sus posibles valores, vamos a aplicar el método One-Hot encoding para transformar las variables en un vector con cada posición reprensentando de forma binaria si la muestra es de esa categoría (1) o si no es de esa categoría (0).  \n",
        "Analizando las variables del conjunto de datos he encontrado dos variables categóricas que no presentan relación de jerarquía entre sus valores que son:\n",
        "\n",
        "*   1 MOSTYPE Customer Subtype   \n",
        "\n",
        "\n",
        "\n",
        "| L0 | Value Label                         |\n",
        "|----|------------------------------------|\n",
        "| 1  | High Income, expensive child        |\n",
        "| 2  | Very Important Provincials          |\n",
        "| 3  | High status seniors                 |\n",
        "| 4  | Affluent senior apartments          |\n",
        "| 5  | Mixed seniors                       |\n",
        "| 6  | Career and childcare                |\n",
        "| 7  | Dinki's (double income no kids)     |\n",
        "| 8  | Middle class families               |\n",
        "| 9  | Modern, complete families           |\n",
        "| 10 | Stable family                       |\n",
        "| 11 | Family starters                     |\n",
        "| 12 | Affluent young families             |\n",
        "| 13 | Young all american family           |\n",
        "| 14 | Junior cosmopolitan                 |\n",
        "| 15 | Senior cosmopolitans                |\n",
        "| 16 | Students in apartments              |\n",
        "| 17 | Fresh masters in the city           |\n",
        "| 18 | Single youth                        |\n",
        "| 19 | Suburban youth                       |\n",
        "| 20 | Ethnically diverse                  |\n",
        "| 21 | Young urban have-nots               |\n",
        "| 22 | Mixed apartment dwellers             |\n",
        "| 23 | Young and rising                    |\n",
        "| 24 | Young, low educated                  |\n",
        "| 25 | Young seniors in the city           |\n",
        "| 26 | Own home elderly                    |\n",
        "| 27 | Seniors in apartments               |\n",
        "| 28 | Residential elderly                 |\n",
        "| 29 | Porchless seniors: no front yard    |\n",
        "| 30 | Religious elderly singles           |\n",
        "| 31 | Low income catholics                 |\n",
        "| 32 | Mixed seniors                        |\n",
        "| 33 | Lower class large families           |\n",
        "| 34 | Large family, employed child         |\n",
        "| 35 | Village families                     |\n",
        "| 36 | Couples with teens 'Married with children'|\n",
        "| 37 | Mixed small town dwellers           |\n",
        "| 38 | Traditional families                |\n",
        "| 39 | Large religous families              |\n",
        "| 40 | Large family farms                   |\n",
        "| 41 | Mixed rurals                         |\n",
        "\n",
        "*   5 MOSHOOFD Customer main type\n",
        "\n",
        "| L2 | Label                    |\n",
        "|----|--------------------------|\n",
        "| 1  | Successful hedonists     |\n",
        "| 2  | Driven Growers           |\n",
        "| 3  | Average Family           |\n",
        "| 4  | Career Loners            |\n",
        "| 5  | Living well              |\n",
        "| 6  | Cruising Seniors         |\n",
        "| 7  | Retired and Religeous    |\n",
        "| 8  | Family with grown ups    |\n",
        "| 9  | Conservative families    |\n",
        "| 10 | Farmers                  |\n"
      ],
      "metadata": {
        "id": "j-EcCG_PhYjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "He encontrado alguna variable más categórica pero representando categorías que tienen un orden en sus valores como la edad o porcentajes.\n",
        "Por lo tanto vamos a plicar One-Hot encoding a esas dos variables utilizando la clase OneHotEncoder utilizando los siguiente parámetros para crear el objeto codificador:\n",
        "*   categories: se especifica la lista categ que contiene las categorías de cada variable.\n",
        "*   sparse_output=False: se establece en False para obtener una matriz densa en lugar de una matriz dispersa, para obtener una matriz con las columnas de cada nueva variable unificadas para añadirlas directamente al conjunto de datos.\n",
        "*   drop=None: se establece en None para mantener todas las categorías en cada variable.\n",
        "Después se utiliza el método fit_transform del objeto codificador para realizar la codificación One-Hot de las variables categóricas elegidas."
      ],
      "metadata": {
        "id": "Tr8TYlkImYsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preproc_trainX = trainX.copy()\n",
        "preproc_testX = testX.copy()\n",
        "\n",
        "variab_categ = [0, 4]  # Variables a codificar\n",
        "\n",
        "trainX_categ = preproc_trainX[:, variab_categ]\n",
        "testX_categ = preproc_testX[:, variab_categ]\n",
        "\n",
        "#Categorias (empiezan en 1)\n",
        "categ_mostype = np.arange(41)+1\n",
        "categ_moshoofd = np.arange(10)+1\n",
        "\n",
        "categ = [categ_mostype,categ_moshoofd]\n",
        "\n",
        "#Funcion para codificar\n",
        "encoder = OneHotEncoder(\n",
        "     categories=categ,  # Categorías de cada variable\n",
        "     sparse_output=False,  # crea una matriz sparse cuando se pone TRUE\n",
        "     drop  = None  #  No quitar categorías en cada variable\n",
        "     )\n",
        "\n",
        "trainX_categ_encoded = encoder.fit_transform(trainX_categ) # Aplicar One Hot Encoding a train\n",
        "testX_categ_encoded = encoder.fit_transform(testX_categ) # Aplicar One Hot Encoding a test\n",
        "\n",
        "# Eliminar las variables categoricas que se han codificado del conjunto original\n",
        "trainX_deleted = np.delete(preproc_trainX, variab_categ, axis=1)\n",
        "testX_deleted = np.delete(preproc_testX, variab_categ, axis=1)\n",
        "\n",
        "# Concatenar las variables sin modificar con las nuevas\n",
        "preproc_trainX = np.concatenate((trainX_deleted, trainX_categ_encoded), axis=1)\n",
        "preproc_testX = np.concatenate((testX_deleted, testX_categ_encoded), axis=1)\n",
        "\n",
        "# Forma del conjunto de datos final\n",
        "print(\"Forma de vector X de muestras tras codificar en training:\",preproc_trainX.shape)\n",
        "print(\"Forma de vector X de muestras tras codificar en test:\",preproc_testX.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COMLBqaYMiu6",
        "outputId": "79f849c3-9626-4715-8aad-aec787a9a962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de vector X de muestras tras codificar en training: (7858, 134)\n",
            "Forma de vector X de muestras tras codificar en test: (1964, 134)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esta codificación hemos conseguido codificar correctamente las variables categóricas aunque hemos añadido una cantidad significativa de variables al conjunto de muestras (como podemos observar en el número de columnas del nuevo conjunto de datos), aumentando la dimesnionalidad del problema en gran medida.  \n",
        "\n",
        "La transformación de estos datos es necesaria que se realice también en el conjunto de test ya que la función entrendad debe recibir los mismos parámetros de entrada al evaluarse con el conjunto de test y al predecir cualquier muestra que durante el entrenamiento."
      ],
      "metadata": {
        "id": "--jo_PQKwE4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Escala del Conjunto de Datos**"
      ],
      "metadata": {
        "id": "ZMLBoDEts7yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a analizar los máximos y mínimos que toman las variables del conjunto de datos de entrenamiento para observar si hay diferencias de escalas entre los distintos parámetros de las muestras. Es importante destacar que estos análisis de los datos han de hacerse únicamente en el conjunto de entrenamiento ya que el econjunto de test es el que será utilizado para evaluar el modelo final y las elecciones tanto del modelo como de las transformaciones no deben influenciarse por la información de este conjunto, y así evitar cometer Data Snooping."
      ],
      "metadata": {
        "id": "uvahk1gdxRI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el valor máximo y mínimo de cada columna en el conjunto de entrenamiento\n",
        "max_values = np.max(preproc_trainX, axis=0)\n",
        "min_values = np.min(preproc_trainX, axis=0)\n",
        "\n",
        "# Crear los nombres de las columnas\n",
        "column_names = np.arange(len(max_values))\n",
        "\n",
        "# Crear histograma de los valores máximos\n",
        "plt.bar(column_names, max_values)\n",
        "plt.xlabel('Columna')\n",
        "plt.ylabel('Valor máximo')\n",
        "plt.title('Valores máximos por columna')\n",
        "plt.show()\n",
        "\n",
        "# Crear histograma de los valores mínimos\n",
        "plt.bar(column_names, min_values)\n",
        "plt.xlabel('Columna')\n",
        "plt.ylabel('Valor mínimo')\n",
        "plt.title('Valores mínimos por columna')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "FpedR7wntSiO",
        "outputId": "702670c9-2959-4db5-fe3a-80c3d9a00b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar en los dos histogramas, los valores máximos de las variables difieren y aunque no es una diferencia enorme, debido a la codificación que hemos realizado antes observamos que hay un conjunto significativo de variables binarias y por tanto podemos aplicar un método de escalado de los datos para que todos los datos se encuentren en la misma escala y así evitar que una variable domine durante el ajuste del modelo. Como podemos observar en los valores mínimos, no se tienen variables negativas y por tanto podemos usar un método de escalado que transforme los datos a una escala entre 0 y 1, y así sigue sin haber variables negativas y se obtiene todas las variables con la misma escala que las binarias, entre 0 y 1. Este escalado se realiza en el apartado 4)"
      ],
      "metadata": {
        "id": "FvdP7EPExhid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora voy a analizar si hay alguna variable que sea constante, esto se puede implementar de muchas maneras, pero si se realiza la resta de los valores máximos menos los valores mínimos, solo las variables constantes tendrán resta 0, y de esta manera utilizamos la información que ya teníamos antes sobre los máximos y mínimos."
      ],
      "metadata": {
        "id": "RHi2W5tD5vEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear histograma de las desviaciones estandar\n",
        "plt.bar(column_names, max_values-min_values)\n",
        "plt.xlabel('Columna')\n",
        "plt.ylabel('Resta Maximo y Mínimo')\n",
        "plt.title('Valores Resta Máximo - Mínimo')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-UAAC-tS465p",
        "outputId": "cc69cad3-0b01-4bfb-eb3b-2fbc6cbf4e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como pdoemos observar en el histográma de las diferencias entre los máximos y mínimos, hay una columna que vale 0."
      ],
      "metadata": {
        "id": "NMKPr--o7lKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables_ctes = []\n",
        "for i in range(len(max_values)):\n",
        "  if(max_values[i]  == min_values[i]): # es equivalente que sean iguales a que su resta sea 0\n",
        "    print('La variable {} es constante'.format(i))\n",
        "    variables_ctes.append(i)\n",
        "if(len(variables_ctes) == 0):\n",
        "  print('No hay variables constantes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqtECMRH6jZs",
        "outputId": "21553e46-4ca5-4f45-fef4-b4f2ce72a239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La variable 96 es constante\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con este último algoritmo hemos detectado que hay una varible que permanece constante en todas las muestras de entrenamiento. Esta variable no proporciona información sobre cada muestra ya que todas las muestras tienen el mismo valor y por tanto al no tener variabilidad no contribuye al modelo para predecir y diferenciar entre ambas clases, por lo tanto podemos eliminar la variable."
      ],
      "metadata": {
        "id": "swuQWoIg7ts4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminar variables constantes:\n",
        "preproc_trainX = np.delete(preproc_trainX, variables_ctes, axis=1)\n",
        "preproc_testX = np.delete(preproc_testX, variables_ctes, axis=1)\n",
        "\n",
        "# Forma del conjunto de datos final\n",
        "print(\"Forma de vector X de muestras tras codificar en training:\",preproc_trainX.shape)\n",
        "print(\"Forma de vector X de muestras tras codificar en test:\",preproc_testX.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDBVeY3W8aD7",
        "outputId": "e8965bd2-4f93-4a3a-d15d-6d4281475002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de vector X de muestras tras codificar en training: (7858, 133)\n",
            "Forma de vector X de muestras tras codificar en test: (1964, 133)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener los máximos y minimos de nuevo:\n",
        "max_values = np.max(preproc_trainX, axis=0)\n",
        "min_values = np.min(preproc_trainX, axis=0)\n",
        "\n",
        "#comprobar variables constantes denuevo\n",
        "variables_ctes = []\n",
        "for i in range(len(max_values)):\n",
        "  if(max_values[i]  == min_values[i]): # es equivalente que sean iguales a que su resta sea 0\n",
        "    print('La variable {} es constante'.format(i))\n",
        "    variables_ctes.append(i)\n",
        "if(len(variables_ctes) == 0):\n",
        "  print('No hay variables constantes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe56b09-aec0-4150-a5ae-145f26709995",
        "id": "wR0QDkIo88ow"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No hay variables constantes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprobamos de nuevo si hay variables constantes para segurarnos de que se han eliminado correctamente, y efectivamente ya no hay variables constantes."
      ],
      "metadata": {
        "id": "db6LRS6T-IKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por el mismo motivo de antes, cuando se han codificado las variables categóricas, como la función clsificadora debe recibir los mismso parámtreos de entrada en el entrenameinto y test, hay que eliminar las variables constantes tanto en entrenamiento como en test."
      ],
      "metadata": {
        "id": "909mDObf90sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>2)  Identificar qué conjuntos de hipótesis se emplearán y justificar dicha elección. 0.25 puntos."
      ],
      "metadata": {
        "id": "9Ozk6Bf-fid4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como modelos lineales podríamos utilizar los siguientes:\n",
        "*   Perceptrón PLA   \n",
        "*   Perceptrón Pocket  \n",
        "*   Regresion Lineal empelada en clasificación\n",
        "*   SVM utilizando un kernel lineal\n",
        "*   Regresión Logística  \n",
        "\n",
        "De entre los posibles modelos lineales voy a utilizar SVM utilizando un kernel lineal y Regresión Logística. He elegido estos modelos ya que el modelo SVM obtiene clasificadores parecidos a los del modelo Perceptrón Pocket pero SVM maximiza la distancia entre las clases obteniendo resultados mejores y convergiendo a un clasificador óptimo, mientras que Perceptrón Pocket que unicamente trata de separar los datos mejorando en cada iteración, utilizando el gradiente de la función de pérdida y quedándose con el mejor clasificador utilizado pero no asegura converger al óptimo. Perceptrón PLA es idéntico a Perceptrón Pocket pero no almacena la mejor solución calculada por lo que obtiene peores clasificadores que utilizando el método Pocket. Por otro lado regresión lineal no es un método generalmente utilizado para clasificación ya que inicialmente está ideado para problemas de regresión donde hace falta predecir valores continuos, y aunque se pueda extender a clasificación no es su enfoque principal.  \n",
        "Regresión logística es un buen modelo que ofrece buenos resultados incluso cuando existe ruido en las muestras ya que estima directamente las probabilidades de pertenecer a cada clase y en base a estas probabilidades clasifica la muestra como la clase con mayor probabilidad.\n",
        "\n",
        "\n",
        "La clase de funciones $\\mathcal{H}$ del modelo SVM con kernel lineal se basan en funciones lineales que son combinaciones lineales de las características de entrada aplicando unos pesos $w$ que son los parámetros que el modelo ajusta durante el aprendizaje. Se emplea un umbral de decisión y dependiendo del valor calculado con la combinación lineal de la entrada se clasifica la muestra. En nuestro caso como las etiquetas de las muestras son representadas por un 0 o un 1, la clase de funciones del modelo SVM es:\n",
        "\n",
        "> $\\mathcal{H} = \\{ h_w|\n",
        "h_w(x) \\ para \\ w \\ fijado\\}$  \n",
        "\n",
        "Con $h_w(x)$:\n",
        "\n",
        ">$h_w(x) =\\left\\{ \\begin{array}{lcc}\n",
        " 0 & si & w^Tx < 0\\\\\n",
        " \\\\ 1 & si & w^Tx \\geq 0\n",
        " \\end{array}\n",
        "   \\right. $\n",
        "\n",
        "donde el número de valores de $w$ dependerá del número de parámetros de cada muestra del conjunto de datos.\n",
        "\n",
        "Las funciones que pertenecen a estas clases son funciones lineaes cuyas fronteras de decisión son hiperplanos en el espacio de los parámetros de los datos. Por ejemplo en el caso del plano, con dos parámetros para los datos, las fronteras de decisión de estas funciones serían rectas que separan el plano en dos mitades, donde cada mitad representa una de las dos clases.  \n",
        "\n",
        "Se eligen estos conjuntos de hipótesis ya que nuestro problema se trata de clasificar dos clases, por lo tanto consiste en separar el espacio paramétrico de los datos en dos partes donde cada parte represente una de las dos clases. Al utilizar modelos lineales, utilizamos funciones lineales que generar estas fronteras de decisión representadas por hiperplanos.\n",
        "\n",
        "Entonces, como las funciones tienen por fronteras de decisión hiperplanos, el algoritmo de aprendizaje será más efectivo cuanto más separables linealmente sean los datos, incluso en algunos casos podrá converger a la solución óptima en el entrenamiento si los datos son completamente linealmente separables.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ibcURnUq7-mr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "La clase de funciones $\\mathcal{H}$ del modelo de regresión lineal se basan también en combinaciones lineales de las características de entrada aplicando unos pesos $w$, pero como lo que se intenta estimar es la probabilidad de pertenecer a una clase u otra, se utiliza una función logística $\\theta$ que transforma el valor de la combinación lineal a un nuevo valor proporcional dentro del intervalo $[0, 1]$ (como la función sigmoide).   \n",
        "\n",
        "Para clasificar, generalmente se elige la clase que tiene mayor probabilidad de contener a la muestra. Se elige de esta forma siguiendo la regla de Bayes que establece que si se conocen la distribución de probabilidad de las clases, el mejor clasificador sería el que clasifique cada muestra en la clase en la que tiene mayor porbabilidad de pertenecer. En nuestro caso como las etiquetas de las muestras son representadas por un 0 o un 1, la clase de funciones del modelo de Regresión Lineal es:\n",
        "\n",
        "> $\\mathcal{H} = \\{ h_w|\n",
        "h_w(x) \\ para \\ w \\ fijado\\}$  \n",
        "\n",
        "Con $h_w(x)$:\n",
        "\n",
        ">$h_w(x) =\\left\\{ \\begin{array}{lcc}\n",
        " 1 & si & \\theta(w^Tx) \\geq 1/2 \\\\\n",
        " \\\\ 0 & & en\\ otro\\ caso\n",
        " \\end{array}\n",
        "   \\right. $\n",
        "\n",
        "Este modelo de Regresión lineal se puede implementar con la clase `sklearn.linear_model.LogisticRegression` de la librería `sklearn`. Sin embargo, con esta implementación de regresión lineal no tenemos el hiperparámetro de la tasa de aprendizaje y por tanto voy a utilizar regresión lineal implementada con Descenso de Gradiente Estocástico (SGD) donde se puede elegir la tasa de aprendizaje que mejor se ajuste al problema, y así poder comparar con más modelos que tengan distintos hiperparámetros con los que provar valores.\n",
        "\n",
        "Al implementar Regresión Logística con SGD, la clase de funciones que explora es la clase de funciones lineal $\\mathcal{H}$ :\n",
        "> $\\mathcal{H} = \\{ h_w|\n",
        "h_w(x) \\ para \\ w \\ fijado\\}$  \n",
        "\n",
        "Con $h_w(x)$:\n",
        "\n",
        ">$h_w(x) =\\left\\{ \\begin{array}{lcc}\n",
        " 0 & si & w^Tx < 0\\\\\n",
        " \\\\ 1 & si & w^Tx \\geq 0\n",
        " \\end{array}\n",
        "   \\right. $\n",
        "\n",
        "que es la misma que con SVM. Como ambos son modelos lineales tiene sentido que tengan la misma clase de funciones ya que las funciones que exploran son lineales con fronteras de decisión hiperplanos que separan el espacio pramétrico en las dos clases."
      ],
      "metadata": {
        "id": "mZ1TmF1rB7fM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>3)  Si la base de datos define conjuntos de training y test, únalos en un solo conjunto y genere sus propios conjuntos. Describa y justifique el mecanismo de partición. 0.75 puntos."
      ],
      "metadata": {
        "id": "4LiijYn4fw_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el apartado 1 ya se ha unido en un solo conjunto todos los datos y han sido separados en training y test con una distribución de 80% training y 20% test como se ha comentado en ese apartado. En el apartado 1) ya se ha explicado las ventajas e inconvenientes de utilizar dsitintas distribuciones para separar los datos en entrenamiento y test."
      ],
      "metadata": {
        "id": "B1MhOIdhWtbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**V-Fold Cross Validation**"
      ],
      "metadata": {
        "id": "zLDrwKrr1NBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el conjunto de datos de entrenamiento voy a utilizar la técnica de V-Fold Cross-Validation (CV) utilizando 10 folds (particiones del conjunto). Esta técnica generalmente ofrece una mejor estimación del error del modelo en la fase de entrenamiento que la estimación utilizando el error de entrenamiento obtenido entrenando el modelo con todos los datos de entrenameinto.\n",
        "\n",
        "La técnica de validación cruzada con V-folds es un método utilizado para evaluar el rendimiento de un modelo de aprendizaje automático de manera más robusta y precisa. Permite utilizar todo el conjunto de datos disponible para entrenar y evaluar el modelo.Esta técnica se basa en dividir el conjunto de datos en V partes iguales (folds) donde cada uno actúa como conjunto de validación una vez, mientras que los subconjutnos restantes se utilizan como conjunto de entrenamiento para ajustar el modelo.Por lo tanto, el modelo se entrena V veces, y en cada vez se utiliza un subconjunto diferente como conjunto de validación. Al final de cada iteración, se obtiene una medida del error o de las métricas elegidas para evaluar el modelo y finalmente se ofrece como estimación final el promedio de las mediciones realizadas en todas las iteraciones.\n",
        "\n",
        "Al utilizar la técnica de V-fold cross-validation, se obtiene una evaluación más confiable del modelo, ya que se utiliza todo el conjunto de datos tanto para entrenar como para validar el modelo. Además, al repetir el proceso V veces con diferentes particiones del conjunto de datos, se reduce el impacto del sesgo en la estimación del rendimiento del modelo.\n",
        "\n",
        "Un valor común para el número de particiones es V = 10, pero puede variar dependiendo del tamaño del conjunto de datos y de la cantidad de datos disponibles. Valores más pequeños de V pueden dar lugar a una estimación menos precisa, mientras que valores más grandes pueden resultar en un coste computacional mayor.\n",
        "\n",
        "Por lo tanto he elegido V = 10  ya que con un número bajo de particiones la estimación del error puede ser poco precisa (al realizar un número menor de estimaciones y particiones del conjunto) y con un número elevado de particiones el coste computaconal es elevado debido al propio coste de la técnica V-Fold Cross-Validation.\n",
        "\n",
        "\n",
        "Debido al desbalanceo significativo de clases que se ha observdo anteriormente (la clase mayoritaria tiene más de un 90% de representación del total), voy a utilizar Stratified V-Fold Cross-Validation, que separa el conjunto de datos en subconjutnos con el mismo porcentaje de representación de cada clase en cada subconjunto.\n",
        "\n",
        "Stratified V-Fold es una variante de la técnica K-fold que tiene en consideración el problema del desbalanceo de clases en el conjunto de datos. Cuando las clases no están representadas de manera equilibrada, como en este conjunto de datos donde hay una diferencia significativa en la cantidad de instancias entre las clases, la validación cruzada que he explicado anteriormente podría generar particiones en las que una o más clases estén subrepresentadas en el conjunto de validación si se eligen las particions de manera uniforme sobre el conjunto de datos.\n",
        "\n",
        "La técnica Stratified V-Fold mantiene una proporción similar de instancias de cada clase en las particiones que genera. Utilizo este método para evitar que la clase minoritaria de este conjunto de datos quede subrepresentada en algunas de las particiones que genera la técnica y afecte a la evluación y entrenamiento del modelo."
      ],
      "metadata": {
        "id": "SjOHt9iwT1ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>4)  Justifique todos los detalles del preprocesado de los datos (codificación, transformación, normalización, etc). Es decir, todas las manipulaciones sobre los datos iniciales que nos permitan fijar el conjunto de vectores de características que se usarán en el entrenamiento. 1 punto.  \n",
        "\n",
        "<font color='blue'>Nota: Las transformaciones no-lineales de las variables pueden definirse a partir de las potencias y\n",
        "productos de potencias de las variables originales, conjuntos de polinomios ortogonales, etc. Si se\n",
        "usan transformaciones no polinómicas de las variable como $log$, $\\sqrt{()}$, $sin$, etc, debe justificar el\n",
        "interés de las mismas."
      ],
      "metadata": {
        "id": "qJykJiQxf30a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Codificación de los datos**"
      ],
      "metadata": {
        "id": "LjjyRZunv9RZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el apartado 1), tras analizar los datos observé que existían dos variables categóricas que no presentaban un orden de jerarquía entre sus valores, y por tanto he aplicado el método One-Hot Encoding a esas dos variables categóricas. Este recodificación de los datos es necesaria para evitar que los algoritmos de aprendizaje automático aprendan una realción o un orden que no existe entre las categorías ya que si por ejemplo se representase la variable categórica como un número entero cada clase, como ocurre en nuestro con caso la variable *MOSTYPE Customer Subtype* que se representa como un número del 1 al 41, cada uno indicando una categoría distinta sin ningún orden entre las categorías, el algoritmo podría sociar una relación de orden o jerarquía entre los valores de la variable incorrecta.  \n",
        "El método One-Hot Encoding, como ya he explicado antes, convierte las variables categóricas representadas por números en una variable como un nuevo vector de columnas binarias para cada categoría dentro de la variable asignando un 1 si pertenece a la categoría y un 0 sino."
      ],
      "metadata": {
        "id": "iyUFwIiFt_U3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Escalado de los datos**"
      ],
      "metadata": {
        "id": "ap07PxDSyziV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como hemos analizado en el apartado 1), el conjutno tiene vairables cuyos valores se encunetran en escalas distintas, entonces para evitar que una característica domine sobre otras durante el ajuste del modelo voy a escalar el conjunto de datos. Como he explicado en el apartado 1) al analizar los máximos y mínimos, he visto que muchas de las características eran binarias debido a la codifiación que he realizado de las variables categóricas y en genera no había valores negativos, por lo tanto he decidido utilizar la funcion `MinMaxScaler` de `sklearn` para escalar todos los datos a una escala entre 0 y 1, como la escala de las variables binarias. El mismo escalado que se aplica en entrenamiento tiene que aplicarse al conjunto de test y no se debe usar infromación del conjunto de test para realizar el escalado, por lo tanto utilizo el metodo `fit()` de `MinMaxScaler` con los datos de entrenamiento para realizar el mismo escalado, que se utiliza en entrenameinto con la infromación del conjunto de entrenameinto, con el conjunto de test. Al codificar varaibles categóricas, hemos añadido las variables binarias que son las ultimas variables desde la 84 hasta la última, y por tanto ya estan en una escala asequible entre 0 y 1, entonces voya aplicar el escalado al resto de las variables."
      ],
      "metadata": {
        "id": "XIZz1LQ6qbLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables_escalar = 83\n",
        "\n",
        "# Escalado Min-Max\n",
        "min_max_scaler = MinMaxScaler(\n",
        "    feature_range = (0,1), # Rango al que escalar los datos\n",
        "    copy = True # Evitar crear una copia de los datos y realizar el escalado directamente en los datos\n",
        ")\n",
        "\n",
        "#ajustar el escalador a los datos de entrenamiento\n",
        "min_max_scaler.fit(preproc_trainX[:,:variables_escalar])\n",
        "\n",
        "# aplicar el escalado a los datos de entrenamiento y test\n",
        "preproc_trainX[:,:variables_escalar] = min_max_scaler.fit_transform(preproc_trainX[:,:variables_escalar]);\n",
        "preproc_testX[:,:variables_escalar] = min_max_scaler.fit_transform(preproc_testX[:,:variables_escalar]);"
      ],
      "metadata": {
        "id": "SJd2M6xUwnx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el valor máximo y mínimo de cada columna en el conjunto de entrenamiento\n",
        "max_values = np.max(preproc_trainX, axis=0)\n",
        "min_values = np.min(preproc_trainX, axis=0)\n",
        "\n",
        "# Crear los nombres de las columnas\n",
        "column_names = np.arange(len(max_values))\n",
        "\n",
        "# Crear histograma de los valores máximos\n",
        "plt.bar(column_names, max_values)\n",
        "plt.xlabel('Columna')\n",
        "plt.ylabel('Valor máximo')\n",
        "plt.title('Valores máximos por columna')\n",
        "plt.show()\n",
        "\n",
        "# Crear histograma de los valores mínimos\n",
        "plt.bar(column_names, min_values)\n",
        "plt.xlabel('Columna')\n",
        "plt.ylabel('Valor mínimo')\n",
        "plt.title('Valores mínimos por columna')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "b61e5110-2bfe-4ed7-ffb8-25eb4b93f02a",
        "id": "E08-XAav1Ga4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar en los nuevos histogramas de los valores máximos y mínimos, los datos han sido escalados correctamente a la escala $[0,1]$. Además podemos observar que no hay variables con mismo valor máximo y mínimo y por tanto no hay variables constantes. Esto se debe a que ya hemos comprobado y eliminado las variables constantes de nuestro cconjunto de datos en el apartado 1)."
      ],
      "metadata": {
        "id": "Vr_w9wd-y4UJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Outliers**\n"
      ],
      "metadata": {
        "id": "EPmRgc959bFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los outliers, o valores atípicos, son observaciones o instancias que se alejan significativamente del resto de los datos en un conjunto de datos. Estos valores atípicos pueden aparecer debido a errores en la medición de los datos o cualquier fuente de ruido que afecte a algunas muestras en el conjunto de datos.Los outliers pueden tener un impacto significativo en el aprendizaje automático, ya que pueden transformar la distribución de los datos y afectar negativamente la calidad del modelo. Este tipo de muestras pueden introducir ruido en los datos e impedir que el modelo pueda separar las clases correctamente provocando una disminución en la precisión y el rendimiento general del clasificador.\n",
        "\n",
        "Una técnica comúnm para tratar de identificar y eliminar los outliers y así reducir su impacto en el aprendizaje automático es el Análisis de Componentes Principales (PCA). PCA es una técnica de reducción de dimensionalidad que busca transformar un conjunto de variables correlacionadas en un conjunto de nuevas variables no correlacionadas y de esta forma reducir la influencia de los outliers y ayudar a mejorar el rendimiento de los modelos.\n",
        "\n",
        "Los outliers pueden ser la principal fuente del error de un modelo pero trata de identificar y demostrar que una muestra se trata de un outlier es difícil y en muchos casos no se puede saber si la muestra es útil para el problema o se trata de ruido en los datos. Algunos valores extremos pueden ser muestras reales que el clasificador debe predecir y no necesariamente deben considerarse outliers. Por ejemplo, en el análisis de fraudes, los valores extremos pueden representar transacciones fraudulentas reales y no muestras generadas por ruido que no deben tenerse en cuenta. Es por esto que la clasificación de las muestras como outliers puede ser muy subjetivo y difícil de demostrar.\n",
        "\n",
        "En nuestro conjunto de datos, al tener una clase con mucha menos representación en el conjunto total de datos, algunas muestras que puedan parecer outliers podrían ser datos relevantes que el clasificador debe predecir y por tanto no deberían eliminarse. Es por esto que en este conjunto de datos no voy a aplicar la técnida de PCA y voy a tratar de tener en cuenta la mayor cantidad de información para intentar clasificar la clase minoritaria igual que la clase mayoritaria."
      ],
      "metadata": {
        "id": "bH3k5RdM9pmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>5)  Justifique las métricas de error y la función de pérdida a usar. Discutir su idoneidad para el problema. 0.5 puntos."
      ],
      "metadata": {
        "id": "3QXdZX5DgM0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Métricas de Error**"
      ],
      "metadata": {
        "id": "n5lUkKiPN6qR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como hemos observado en el apartado 1), hay un desbalanceo significativo entre ambas clases, ya que una de las clases tiene una representación de más del 90% del total mientras que la otra tiene menos del 10% del total. Como he explicado antes, debido a este desbalanceo, será necesario utilizar métricas de error distintas de la métrica de accuracy, ya que un clasificador que clasifique todas las muestras como la clase mayoritaria obtendría una calificación de más del 90% en accuracy y por tanto obtener un porcentaje alto de más del 90% en accuracy no es un buen indicador de éxito al evaluar un modelo en este problema.  \n",
        "\n",
        "Tomando la clase mayoritaria (0) como la clase negativa y la clase minoritaria (1) como la clase positiva, voy a utiliza las siguientes métricas:\n",
        "\n",
        "\n",
        "*   Precisión: La precisión se calcula como  $\\frac{TP}{TP+FP}$.  \n",
        "Esta métrica, por cómo se calcula, mide la proporción de casos positivos correctamente clasificados respecto de todas las predicciones positivas. Entonces en nuestro problema es útil esta métrica ya que penaliza los falsos positivos (clasificar de forma incorrecta la clase minoritaria) y valora los positivos verdaderos (clasificar de forma correcta la clase minoritaria)\n",
        "*   Recall: se calcula como $\\frac{TP}{TP+FN} = \\frac{TP}{P}$.  \n",
        "Mide la proporción de casos positivos correctamente identificados respecto al total de casos positivos reales. Sirve para verificar si el modelo está identificando correctamente los casos positivos y evitando falsos negativos.\n",
        "*   F1-Score: se calcula como $2 *\\frac{ Precision * Recall}{Precision + Recall}$.   \n",
        "Combina la precisión y el recall en una única medida y por lo tanto es útil también en problemas con desbalanceo de clases. Proporciona un equilibrio entre la precisión y el recall, ofreciendo una valoración más general del modelo que las dos métricas anteriores.\n",
        "\n",
        "Como notación estoy utilizando:  \n",
        "$TP$: verdaderos positivos.  \n",
        "$FP$: falsos positivos.  \n",
        "$TN$: verdaderos negativos.  \n",
        "$FN$: falsos negativos.  \n",
        "\n",
        "Para implementar estas métricas voy a utilizar la función `make_scorer` de `sklearn.metrics` que se utiliza para crear un objeto puntuador (scorer) a partir de una métrica o función de pérdida. Utilizo esta función para poder utilizar la función `cross_validate` que recibe como parámetro de entrada un modelo (*estimator* que implemente la función fit ), unos datos de entrada (*X*), las etiquetas correspondientes a los datos (*Y*), un generador de cross-validation (*cv*) y una lista con las metricas (scores) que se pretenden evaluar (*scoring*). Existen otras métricas denominadas macro que a partir de las métricas usuales, calculan cada una de las métricas por clases y despúes realizan el promedio. Por ejemplo para la métrica `'precision'` existe `'precision_macro'`. Estas métricas al evaluar las clases por separado no tienen en cuenta el desbalanceo de clases y por lo tanto no son las que he elegido para evaluar mis modelos ya que en este conjunto de datos existe desbalanceo de clases en gran medida. Por eso utilizo `make_scorer` para crear objetos puntuadores a aprtir de las métrcias que que he elegido y he explicado anteriormente.\n"
      ],
      "metadata": {
        "id": "ehvmrCB9KPyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Funciones de Pérdida**"
      ],
      "metadata": {
        "id": "-N_ytRCdN6Av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El error que generlamente se utiliza en Regresión Logística es el error de entropía cruzada (\"cross-entropy\" error) que se obtiene a partir de la siguiente formula:\n",
        ">$E_{in}(w) = \\frac{1}{N} \\sum_{n=1}^{N} ln(1 + e^{-y_n w^T x_n})$\n",
        "\n",
        "Esta formula se obtiene al tratar de maximizar la probabilidad de obtener el vector de pesos w que clasifica cada muestra correctamente siendo $ s = \\{(x_1, y_1),...,(x_N, y_N)\\}$ las distribución de etiquetas correctas:\n",
        ">$L(s) = \\prod_{i=1}^{N} P_w(y_i|x_i) = \\prod_{i=1}^{N} \\theta (y_n w^T x_n)$  \n",
        "\n",
        "Para conseguirlo podemos minimizar:  \n",
        ">$-\\frac{1}{N} ln(L(s))=-\\frac{1}{N} ln(\\prod_{i=1}^{N} \\theta (y_n w^T x_n)) = \\frac{1}{N} \\sum_{n=1}^{N} ln(1 + e^{-y_n w^T x_n})$\n",
        "\n",
        "Que es justo la expresión del error de entropía cruzada:\n",
        "\n",
        ">$E_{in}(w) = \\frac{1}{N} \\sum_{n=1}^{N} ln(1 + e^{-y_n w^T x_n})$\n",
        "\n",
        "En la clase `SGDClassifier` se especifica la función de pérdida a usar con el parámetro `Loss` y en nuestro caso para implementar regresión logística se emplea 'log_loss' que es la función de pérdida asociada a este modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "_j8BI3Jiv4yM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo de SVM que estamos implementando es el modelo de SVM con margen suave (soft-margin SVM). El objetivo de este modelo es encontrar un hiperplano de separación que maximice el margen entre las clases, permitiendo cierto grado de error de clasificación en las muestras de entrenamiento.\n",
        "\n",
        "El error utilizado en SVM se define como:\n",
        "\n",
        ">$E_{SVM}(b,w) = \\frac{1}{N} \\sum_{n=1}^{N} max(1 -y_n( w^T x_n+ b),0)$\n",
        "\n",
        "donde $N$ es el número de muestras de entrenamiento, $x_n$ es una muestra de entrenamiento, $y_n$ es su etiqueta correspondiente, $w$ es el vector de pesos y $b$ es el sesgo del hiperplano de separación.\n",
        "\n",
        "La fucnión $max(1 -y_n( w^T x_n+ b),0)$ es la función de pérdida *hinge*, que mide la distancia entre una muestra y el hiperplano de separación. Si la muestra está clasificada correctamente, entonces $y_n(w^T x_n + b) \\geq 1$) y el error es cero. Si la muestra está clasificada incorrectamente, entonces $y_n(w^T x_n + b) < 1$) y el error es proporcional a la distancia entre la muestra y el hiperplano de separación.\n",
        "\n",
        "Para encontrar los valores óptimos de $w$ y $b$ que minimizan este error, se utiliza la optimización cuadrática *QP*. El objetivo es encontrar los valores de $w$ y $b$ que minimizan el error, a la vez que se penalizan los valores grandes de $w$ para evitar el sobreajuste. Esta penalización se logra a través del término de regularización $w^T w$ en la función de pérdida.\n",
        "\n",
        "En resumen, el modelo de SVM con margen suave utiliza la función de pérdida hinge y un término de regularización para encontrar un hiperplano de separación óptimo que maximice el margen entre las clases y permita cierto grado de error de clasificación. Por lo tanto se puede observar este modelo como un caso especial de clasificación con regularización utilizando la función de pérdida $E_{SVM}$ y $w^{T}w$ como el regularizador."
      ],
      "metadata": {
        "id": "0ALoyasqzCEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>6)  Discuta todos los parámetros y el tipo de regularización usada en el ajuste de los modelos seleccionados. Justificar la idoneidad de la regularización elegida. 1 punto."
      ],
      "metadata": {
        "id": "S4Lo3fC0g6Cv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Regularización**"
      ],
      "metadata": {
        "id": "CS5zDuK-fFah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La regularización L2 y la regularización L1 son dos técnicas de regularización en aprendizaje automático para evitar el sobreajuste de los modelos y ofrecer un ajuste del modelo con menos variabilidad descontrolada. Ambas se basas en aplicar unos parámetros de regularización sobre el modelo durante el entrenamiento.\n",
        "\n",
        "La regularización L2 (Ridge) tarata de penalizar los valores grandes de los coeficientes del modelo y tiende a reducirlos. Este tipo de regularización consigue que los coeficientes no nulos tienden a disminuir hacia cero, pero nunca se anulan por completo. Esto hace que la regularización L2 sea menos propensa a seleccionar características irrelevantes, anulando las importantes y por tanto sea más adecuada para conjuntos de datos con muchas características.\n",
        "\n",
        "La regularización L1 (Lasso) penaliza los valores grandes de los coeficientes y también tiende a reducirlos. Esta regularización puede anular completamente los coeficientes y convertirlos en cero, lo que implica que puede elegir las características que consider más relevantes y anular las que considera menos relevantes. Esto hace que la regularización L1 sea útil en situaciones en las que se desea realizar una selección de características, pero también hace que no sea adecuada para conjuntos de datos donde se piensa que todas o casi todas las características son relevantes.\n",
        "\n",
        "En un conjunto de datos de clasificación con clases desbalanceadas, como ocurre con este conjunto de datos, la regularización L2 tiende a funcionar mejor que la regularización L1 ya que la regularización L2 penaliza los coeficientes de manera proporcional a su magnitud, sin tener en cuenta la clase a la que pertenecen las muestras y no anula variables del conjunto que podrían ser importantes para identificar correctemante la clase mayoritaria. Esto permite que el modelo se ajuste de manera más equilibrada a todas las clases, evitando un sesgo hacia la clase mayoritaria.\n",
        "\n",
        "Por lo tanto en ambos modelos voy a emplear la regularización L2(Ridge)."
      ],
      "metadata": {
        "id": "AWTA9MJUFq_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Ajuste de Regresión Logística**"
      ],
      "metadata": {
        "id": "mwP7NP6BGGSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a emplear el tipo de regularización L2 (Ridge) utilizando el parámetro `penalty` con el valor `'l2'` que representa esta regularización. Como he explicado antes, he elegido la regularización L2 ya que L1 tiende a establecer el valor de los pesos de regularizción a cero de las variables que considera menos relevantes y debido al significativo desbalanceo de clases que existe en el conjunto de datos, puede haber variables relevantes para la clase minoritaria que se vean perjudicadas o anuladas por la regularización. Por lo tanto como L2 tiene en cuenta todas las variables, he elegido esta regularización. La constante de regularización se elige experimentalmente con diversos valores incluyendo el valor cero para comparar con modelos que no implementen regularización también."
      ],
      "metadata": {
        "id": "l8jKMDwtaCTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prámetros del modelo de Regresión Logística empleando SGD con la clase `SGDClassifier`:\n",
        "\n",
        "*   Loss: especifica la función de pérdida utilizada para la regresión logística. En este caso, se utiliza 'log_loss' para la regresión logística.\n",
        "\n",
        "*   Penalty: especifica el tipo de regularización a utilizar, como L1 o L2.\n",
        "\n",
        "*   Alpha: es el parámetro de regularización en la Regresión Logística con SGD. Controla la fuerza de regularización que se pretende usar, cuanto mayor es el valor alpha, más regularización se aplica.\n",
        "\n",
        "*   Learning Rate: la tasa de aprendizaje utilizada en el Descenso de Gradiente Estocástico. Determina el tamaño del paso que se toma en cada iteración del algoritmo. Se utiliza learning_rate para determinar el tipo (constante, adaptativo...) y eta0 para darle un valor al leraning rate. En nuestro caso usaremos constante para el tipo y probaremos con distintos valores para poder comparar y escoger con el que se obtengan mejores resultados.\n",
        "\n",
        "*   Max_iter: número máximo de iteraciones.\n",
        "\n",
        "*   Random_state: establece la semilla para los números aleatorios generados para desordenar los datos.\n",
        "*   Shuffle: determina si se desordenan las muestras después de cada época.\n",
        "*   tol: tolerancia usada para el criterio de parada y convergencia del algoritmo de SGD. En esta clase este parámetro se utiliza para determinar si el algoritmo ha convergido comparando la disminución de la función de pérdida. Un valor menor podría aumentar el tiempo de cómputo y un valor mayor de este parámetro podría hacer que el algoritmo parase antes de converger al óptimo.\n",
        "*   class_weight: Parámetro que permite determinar los pesos para cada clase y penalizar los errores y valorar los aciertos en la clase con mayor peso"
      ],
      "metadata": {
        "id": "pBg7uzexdQ9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Ajuste SVM kernel lineal**"
      ],
      "metadata": {
        "id": "tuL4o3oUS06E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prámetros del modelo de Regresión Logística empleando SGD con la clase `SVC` de `sklearn.svm`:\n",
        "*   Kernel: Tipode kernel utilizado en el algoritmo SVM. Con el kernel lineal se obtiene un modelo lineal.\n",
        "*   Random_state: establece la semilla para los números aleatorios generados para desordenar los datos.\n",
        "*   tol: tolerancia usada para el criterio de parada de convergencia.\n",
        "*   class_weight: Parámetro que permite determinar los pesos para cada clase y penalizar los errores y valorar los aciertos en la clase con mayor peso (parámetro parecido al que se usa en la clase `SGDClassifier`)\n",
        "\n",
        "*   C: es el parámetro de regularización. Controla la fuerza de regularización que se pretende usar, cuanto mayor es el valor alpha, más regularización se aplica.\n",
        "\n",
        "*   Max_iter: número máximo de iteraciones. Si se establece a -1 se utilizan otros criterios de parada y la convergencia del algoritmo.\n",
        "\n",
        "La clase `SVC` implementa el tipo de regularización L2 (Ridge) que se ajusta con el parámetro de entrada C. Como el proceso de regularización es parte del algoritmo utilizado en este modelo no se puede eliminar la regularización, por lo tanto la constante C no puede tomar el valor de 0 en este modelo."
      ],
      "metadata": {
        "id": "IIydO5noS06E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debido al desbalanceo que ya he explicado de ambas clases, los modelos que se entrenen podrían tender a clasificar casi todas las muestras como la clase mayoritaria. Para evitar esto se puede aplicar unos pesos de penalización en el algoritmo a cada clase para penalizar los errores de la clase con mayor peso y favorecer los aciertos de la clase con mayor peso. De esta forma se puede evitar que el clasificador identifique peor en gran medida la clase minoritaria que la mayoritaria."
      ],
      "metadata": {
        "id": "lG9RAe6DijEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>7)  Selección de la mejor hipótesis para el problema. Discuta el enfoque seguido y el criterio de selección usado. ¿Cúal es su error $E_{out}$? 1 punto."
      ],
      "metadata": {
        "id": "wUknqHBtg8DP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Ajuste de Regresión Logística**"
      ],
      "metadata": {
        "id": "7LX7lePqjzBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los hiperparámetros que voy a elegir experimentalmente utilizando la validación cruzada, explicada anteriormente, para el modelo de Regresión logística son:\n",
        "\n",
        "\n",
        "*   Tasa de aprendizaje (learning rate)\n",
        "*   Constante de regularización de tipo L2 (Ridge)\n",
        "*   Pesos de penalización de las clases\n",
        "\n"
      ],
      "metadata": {
        "id": "TD6eJCLIiGk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras probar con valores extremos he conseguido acotar los valores de cada hiperparámetro para poder mostrar sus resultados en una tabla y elegir los hiperparámetros con los que se obtiene un mejor modelo entrenado de Regresión logística.  \n",
        "\n",
        "En la tabla se representan las métricas que he comentado anteriormente junto con la función de pérdida, calculados medainte la validación cruzada explicada en los apartados anteriores."
      ],
      "metadata": {
        "id": "ibYVAlHHjUXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inicializar listas para guardar valores para la tabla\n",
        "tasasTabla = []\n",
        "alphaTabla = []\n",
        "class_weightTabla = []\n",
        "\n",
        "funcionPerdidaTabla = []\n",
        "accuracyTabla = []\n",
        "recallTabla = []\n",
        "f1Tabla = []\n",
        "precisionTabla = []\n",
        "\n",
        "# métricas para utilizar\n",
        "scoringRL = {'accuracy': 'accuracy',\n",
        "           'precision': make_scorer(precision_score, zero_division = 0),\n",
        "            # zero_division = 0 sirve para que cuando el calsificador no predice ninguan muestra\n",
        "            # como una de las clases, la métrica sea 0 directamente y eliminar un Warning que indicaba justo eso\n",
        "           'recall': make_scorer(recall_score),\n",
        "           'f1_score': make_scorer(f1_score),\n",
        "           'neg_log_loss': 'neg_log_loss',\n",
        "           # Utilizo la función de pérdida negativa ya que cross validate usa funciones de evaluación que intenten\n",
        "           # maximizar y log_loss sirve para minimizar, por eso uso la función neg_log_loss que es equivalente pero para maximizar\n",
        "           }\n",
        "\n",
        "#Ejecutar el algoritmo con valores distintos para lr\n",
        "tasas = [0.01, 0.1, 1]\n",
        "alphaValues = [0, 0.001, 0.01]\n",
        "alpha = 0.001\n",
        "tipoRegul = 'l2'\n",
        "class_weight_values = [{0: 1, 1: 3},{0: 1, 1: 4},{0: 1, 1: 5}]\n",
        "max_iters = 1000\n",
        "for lr in tasas:\n",
        "  for alpha in alphaValues:\n",
        "    for class_weight_val in class_weight_values:\n",
        "      # Crear el modelo de Regresión Logística SGD con los parámetros elegidos\n",
        "      RL_SGD_modelo = SGDClassifier(\n",
        "          loss = 'log_loss', # Determinar lunción de pérdida asociada al modelo de regresión logística (log_loss)\n",
        "          max_iter = max_iters, #número máximo de iteraciones\n",
        "          random_state=1, # Establecer semilla para los numero aleatorios generados para desordenar los datos\n",
        "          shuffle = True, # Desordenar muestras después de cada época,\n",
        "          learning_rate = 'constant', # Determinar que el learning rate sea constante, elegido por parámetro eta0\n",
        "          eta0 = lr, # Elegir tasa de aprendizaje constante que utilizará SGD\n",
        "          penalty = tipoRegul, # Elegir tipo de regularización\n",
        "          alpha = alpha, # parametro de reularización\n",
        "          tol = 1e-3, # tolerancia del criterio de parada por defecto\n",
        "          class_weight=class_weight_val # Determina los pesos de las clases\n",
        "          )\n",
        "      # Crear el objeto K-fold con 10 divisiones\n",
        "      kfold = StratifiedKFold(\n",
        "          n_splits=10, # Número de particiones (folds)\n",
        "          random_state=0, # Semilla para los números aleatorios\n",
        "          shuffle=True #Desordenar por clases antes de particionar el conjunto\n",
        "          )\n",
        "      # Realizar validación cruzada y obtener los resultados de varias métricas\n",
        "      results = cross_validate(RL_SGD_modelo, preproc_trainX, trainY, cv=kfold, scoring=scoringRL)\n",
        "\n",
        "      #guardar datos para la tabla\n",
        "      tasasTabla.append(lr)\n",
        "      alphaTabla.append(alpha)\n",
        "      class_weightTabla.append(class_weight_val)\n",
        "\n",
        "      accuracyTabla.append(results['test_accuracy'].mean())\n",
        "      precisionTabla.append(results['test_precision'].mean())\n",
        "      recallTabla.append(results['test_recall'].mean())\n",
        "      f1Tabla.append(results['test_f1_score'].mean())\n",
        "      funcionPerdidaTabla.append(-results['test_neg_log_loss'].mean())#  Cambiar de signo la funcion de pérdida negativa\n",
        "\n",
        "\n",
        "#Crear DataFrame y mostrarlo\n",
        "tableFrame = pd.DataFrame({'Tasa de aprendizaje': tasasTabla, 'Parámetro de regularización': alphaTabla,\n",
        "                          'Class weights (penalización de clases)': class_weightTabla,'Error de validación (función de pérdida)':funcionPerdidaTabla,\n",
        "                           'Accuracy':accuracyTabla,'Precision': precisionTabla,'Recall':recallTabla,'F1-Score':f1Tabla})\n",
        "display(tableFrame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "H5TYiCo2zHGO",
        "outputId": "0c4c57b5-bd0a-488b-bdec-afd52136b319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Tasa de aprendizaje  Parámetro de regularización  \\\n",
              "0                  0.01                        0.000   \n",
              "1                  0.01                        0.000   \n",
              "2                  0.01                        0.000   \n",
              "3                  0.01                        0.001   \n",
              "4                  0.01                        0.001   \n",
              "5                  0.01                        0.001   \n",
              "6                  0.01                        0.010   \n",
              "7                  0.01                        0.010   \n",
              "8                  0.01                        0.010   \n",
              "9                  0.10                        0.000   \n",
              "10                 0.10                        0.000   \n",
              "11                 0.10                        0.000   \n",
              "12                 0.10                        0.001   \n",
              "13                 0.10                        0.001   \n",
              "14                 0.10                        0.001   \n",
              "15                 0.10                        0.010   \n",
              "16                 0.10                        0.010   \n",
              "17                 0.10                        0.010   \n",
              "18                 1.00                        0.000   \n",
              "19                 1.00                        0.000   \n",
              "20                 1.00                        0.000   \n",
              "21                 1.00                        0.001   \n",
              "22                 1.00                        0.001   \n",
              "23                 1.00                        0.001   \n",
              "24                 1.00                        0.010   \n",
              "25                 1.00                        0.010   \n",
              "26                 1.00                        0.010   \n",
              "\n",
              "   Class weights (penalización de clases)  \\\n",
              "0                            {0: 1, 1: 3}   \n",
              "1                            {0: 1, 1: 4}   \n",
              "2                            {0: 1, 1: 5}   \n",
              "3                            {0: 1, 1: 3}   \n",
              "4                            {0: 1, 1: 4}   \n",
              "5                            {0: 1, 1: 5}   \n",
              "6                            {0: 1, 1: 3}   \n",
              "7                            {0: 1, 1: 4}   \n",
              "8                            {0: 1, 1: 5}   \n",
              "9                            {0: 1, 1: 3}   \n",
              "10                           {0: 1, 1: 4}   \n",
              "11                           {0: 1, 1: 5}   \n",
              "12                           {0: 1, 1: 3}   \n",
              "13                           {0: 1, 1: 4}   \n",
              "14                           {0: 1, 1: 5}   \n",
              "15                           {0: 1, 1: 3}   \n",
              "16                           {0: 1, 1: 4}   \n",
              "17                           {0: 1, 1: 5}   \n",
              "18                           {0: 1, 1: 3}   \n",
              "19                           {0: 1, 1: 4}   \n",
              "20                           {0: 1, 1: 5}   \n",
              "21                           {0: 1, 1: 3}   \n",
              "22                           {0: 1, 1: 4}   \n",
              "23                           {0: 1, 1: 5}   \n",
              "24                           {0: 1, 1: 3}   \n",
              "25                           {0: 1, 1: 4}   \n",
              "26                           {0: 1, 1: 5}   \n",
              "\n",
              "    Error de validación (función de pérdida)  Accuracy  Precision    Recall  \\\n",
              "0                                   0.247525  0.927588   0.225878  0.078413   \n",
              "1                                   0.267856  0.919315   0.256425  0.144105   \n",
              "2                                   0.288556  0.909004   0.223444  0.200931   \n",
              "3                                   0.257553  0.927460   0.254111  0.080452   \n",
              "4                                   0.284935  0.916639   0.269183  0.173404   \n",
              "5                                   0.293214  0.909763   0.226909  0.183998   \n",
              "6                                   0.258147  0.937134   0.092460  0.021277   \n",
              "7                                   0.296694  0.927588   0.179140  0.095434   \n",
              "8                                   0.325768  0.914985   0.253661  0.150089   \n",
              "9                                   0.320103  0.881406   0.232100  0.135771   \n",
              "10                                  0.332800  0.881276   0.282197  0.159131   \n",
              "11                                  0.258688  0.920840   0.252528  0.114229   \n",
              "12                                  0.303714  0.887006   0.150242  0.091445   \n",
              "13                                  0.232805  0.933315   0.177692  0.036082   \n",
              "14                                  0.274386  0.904178   0.277607  0.121055   \n",
              "15                                  0.225049  0.938153   0.000000  0.000000   \n",
              "16                                  0.245156  0.925684   0.022523  0.041755   \n",
              "17                                  0.248473  0.925302   0.035152  0.043794   \n",
              "18                                  1.106978  0.885198   0.177915  0.183511   \n",
              "19                                  1.964063  0.807608   0.185493  0.312766   \n",
              "20                                  3.027352  0.783696   0.151940  0.337278   \n",
              "21                                  0.822859  0.928990   0.060346  0.029787   \n",
              "22                                  1.081049  0.872367   0.115017  0.170833   \n",
              "23                                  1.202272  0.886239   0.120986  0.133954   \n",
              "24                                  0.671373  0.905073   0.019337  0.070213   \n",
              "25                                  0.789767  0.897949   0.031808  0.082979   \n",
              "26                                  1.266595  0.845644   0.045039  0.131871   \n",
              "\n",
              "    F1-Score  \n",
              "0   0.104360  \n",
              "1   0.155855  \n",
              "2   0.196570  \n",
              "3   0.109822  \n",
              "4   0.187848  \n",
              "5   0.184669  \n",
              "6   0.032867  \n",
              "7   0.117247  \n",
              "8   0.161730  \n",
              "9   0.094162  \n",
              "10  0.126917  \n",
              "11  0.139068  \n",
              "12  0.040095  \n",
              "13  0.051994  \n",
              "14  0.083803  \n",
              "15  0.000000  \n",
              "16  0.027628  \n",
              "17  0.026068  \n",
              "18  0.116972  \n",
              "19  0.148905  \n",
              "20  0.139984  \n",
              "21  0.037213  \n",
              "22  0.110654  \n",
              "23  0.084701  \n",
              "24  0.026151  \n",
              "25  0.024233  \n",
              "26  0.043986  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9635872b-cb47-4acc-8539-ffe4780ba828\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tasa de aprendizaje</th>\n",
              "      <th>Parámetro de regularización</th>\n",
              "      <th>Class weights (penalización de clases)</th>\n",
              "      <th>Error de validación (función de pérdida)</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.000</td>\n",
              "      <td>{0: 1, 1: 3}</td>\n",
              "      <td>0.247525</td>\n",
              "      <td>0.927588</td>\n",
              "      <td>0.225878</td>\n",
              "      <td>0.078413</td>\n",
              "      <td>0.104360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.000</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>0.267856</td>\n",
              "      <td>0.919315</td>\n",
              "      <td>0.256425</td>\n",
              "      <td>0.144105</td>\n",
              "      <td>0.155855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.000</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>0.288556</td>\n",
              "      <td>0.909004</td>\n",
              "      <td>0.223444</td>\n",
              "      <td>0.200931</td>\n",
              "      <td>0.196570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{0: 1, 1: 3}</td>\n",
              "      <td>0.257553</td>\n",
              "      <td>0.927460</td>\n",
              "      <td>0.254111</td>\n",
              "      <td>0.080452</td>\n",
              "      <td>0.109822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>0.284935</td>\n",
              "      <td>0.916639</td>\n",
              "      <td>0.269183</td>\n",
              "      <td>0.173404</td>\n",
              "      <td>0.187848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>0.293214</td>\n",
              "      <td>0.909763</td>\n",
              "      <td>0.226909</td>\n",
              "      <td>0.183998</td>\n",
              "      <td>0.184669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.010</td>\n",
              "      <td>{0: 1, 1: 3}</td>\n",
              "      <td>0.258147</td>\n",
              "      <td>0.937134</td>\n",
              "      <td>0.092460</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.032867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.010</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>0.296694</td>\n",
              "      <td>0.927588</td>\n",
              "      <td>0.179140</td>\n",
              "      <td>0.095434</td>\n",
              "      <td>0.117247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.010</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>0.325768</td>\n",
              "      <td>0.914985</td>\n",
              "      <td>0.253661</td>\n",
              "      <td>0.150089</td>\n",
              "      <td>0.161730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.000</td>\n",
              "      <td>{0: 1, 1: 3}</td>\n",
              "      <td>0.320103</td>\n",
              "      <td>0.881406</td>\n",
              "      <td>0.232100</td>\n",
              "      <td>0.135771</td>\n",
              "      <td>0.094162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.000</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>0.332800</td>\n",
              "      <td>0.881276</td>\n",
              "      <td>0.282197</td>\n",
              "      <td>0.159131</td>\n",
              "      <td>0.126917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.000</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>0.258688</td>\n",
              "      <td>0.920840</td>\n",
              "      <td>0.252528</td>\n",
              "      <td>0.114229</td>\n",
              "      <td>0.139068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{0: 1, 1: 3}</td>\n",
              "      <td>0.303714</td>\n",
              "      <td>0.887006</td>\n",
              "      <td>0.150242</td>\n",
              "      <td>0.091445</td>\n",
              "      <td>0.040095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>0.232805</td>\n",
              "      <td>0.933315</td>\n",
              "      <td>0.177692</td>\n",
              "      <td>0.036082</td>\n",
              "      <td>0.051994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>0.274386</td>\n",
              "      <td>0.904178</td>\n",
              "      <td>0.277607</td>\n",
              "      <td>0.121055</td>\n",
              "      <td>0.083803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>{0: 1, 1: 3}</td>\n",
              "      <td>0.225049</td>\n",
              "      <td>0.938153</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>0.245156</td>\n",
              "      <td>0.925684</td>\n",
              "      <td>0.022523</td>\n",
              "      <td>0.041755</td>\n",
              "      <td>0.027628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>0.248473</td>\n",
              "      <td>0.925302</td>\n",
              "      <td>0.035152</td>\n",
              "      <td>0.043794</td>\n",
              "      <td>0.026068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>{0: 1, 1: 3}</td>\n",
              "      <td>1.106978</td>\n",
              "      <td>0.885198</td>\n",
              "      <td>0.177915</td>\n",
              "      <td>0.183511</td>\n",
              "      <td>0.116972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>1.964063</td>\n",
              "      <td>0.807608</td>\n",
              "      <td>0.185493</td>\n",
              "      <td>0.312766</td>\n",
              "      <td>0.148905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>3.027352</td>\n",
              "      <td>0.783696</td>\n",
              "      <td>0.151940</td>\n",
              "      <td>0.337278</td>\n",
              "      <td>0.139984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{0: 1, 1: 3}</td>\n",
              "      <td>0.822859</td>\n",
              "      <td>0.928990</td>\n",
              "      <td>0.060346</td>\n",
              "      <td>0.029787</td>\n",
              "      <td>0.037213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>1.081049</td>\n",
              "      <td>0.872367</td>\n",
              "      <td>0.115017</td>\n",
              "      <td>0.170833</td>\n",
              "      <td>0.110654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>1.202272</td>\n",
              "      <td>0.886239</td>\n",
              "      <td>0.120986</td>\n",
              "      <td>0.133954</td>\n",
              "      <td>0.084701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.010</td>\n",
              "      <td>{0: 1, 1: 3}</td>\n",
              "      <td>0.671373</td>\n",
              "      <td>0.905073</td>\n",
              "      <td>0.019337</td>\n",
              "      <td>0.070213</td>\n",
              "      <td>0.026151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.010</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>0.789767</td>\n",
              "      <td>0.897949</td>\n",
              "      <td>0.031808</td>\n",
              "      <td>0.082979</td>\n",
              "      <td>0.024233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.010</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>1.266595</td>\n",
              "      <td>0.845644</td>\n",
              "      <td>0.045039</td>\n",
              "      <td>0.131871</td>\n",
              "      <td>0.043986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9635872b-cb47-4acc-8539-ffe4780ba828')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9635872b-cb47-4acc-8539-ffe4780ba828 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9635872b-cb47-4acc-8539-ffe4780ba828');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para elegir los hiperparámetros hay que observar las métricas en detalle, ya que como hemos explicado antes la métrica accuracy en este problema no tiene en consideración el desbalanceo de las clases y por tanto hay que observar también las otras métricas obtenidas para asegurarse de que ambas clases son identificadas de igual forma y el clasificador no tienda a clasificar todas las muestras como la clase mayoritaria. Como podemos observar en la tabla, el clasficador con mejor error de validación y accuracy que ha obtenido el algoritmo es el clasificador que obtiene un porcetnaje de accuracy igual al porcentaje de la clase mayoritaria en el conjunto de datos, que es justo el clasificador que identifica todas las muestras como la clase mayoritaria. si observamos las otras métrcias, este clasificador obtiene de valor cero en esas otras métrcias que se centran en los aciertos y fallos de la clase minoriataria, y por lo tanto podemos afirmar que no esta clasificando correctamente la clase minoritaria. Como nuestro objetivo es encontrar la mejor hipótesis para el problema, un clasificador que identifique todas las muestras como la clase mayoritaria no es un buen resultado y por lo tanto vamos a optar por un clasificador que obtenga mejores resultados en las métricas de Recall, Precision y F1-Score.\n",
        "\n",
        "Teniendo en cuenta las consideraciones anteriores, he considerador el mejor modelo el que se ha generado con los parámetros de tasa de aprendizaje $\\eta = 0.01$, constante de regularización $alpha = 0.001$ y proporción de pesos de clases (penzalización) de ${0: 1, 1: 4}$ (que representa un peso de la clase minoritaria 4 veces mayor que la clase mayoritaria). Este modelo es el segundo modelo con mejor valor en la métrica F1-Score, tiene valores de Precision y Recall bastantes altos en comparación con el resto y mantiene un valor de accuracy de más del 90%, por lo que la diferencia con el mejor no es significativa."
      ],
      "metadata": {
        "id": "HMMifQ8qk2Ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Ajuste SVM kernel lineal**"
      ],
      "metadata": {
        "id": "oCK5T52WlDL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los hiperparámetros que voy a elegir experimentalmente utilizando la validación cruzada, explicada anteriormente, para el modelo de SVM con kernel lineal son:\n",
        "\n",
        "\n",
        "*   Constante de regularización de tipo L2 (Ridge)\n",
        "*   Pesos de penalización de las clases\n",
        "\n"
      ],
      "metadata": {
        "id": "9h3Rr_rMTRbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Ignorar el warning ConvergenceWarning para que la salida esté más clara\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "#Inicializar listas para guardar valores para la tabla\n",
        "CTabla = []\n",
        "class_weightTabla = []\n",
        "\n",
        "funcionPerdidaTabla = []\n",
        "accuracyTabla = []\n",
        "recallTabla = []\n",
        "f1Tabla = []\n",
        "precisionTabla = []\n",
        "\n",
        "# métricas para utilizar\n",
        "scoringSVM = {'accuracy': 'accuracy',\n",
        "           'precision': make_scorer(precision_score, zero_division = 0),\n",
        "            # zero_division = 0 sirve para que cuando el calsificador no predice ninguan muestra\n",
        "            # como una de las clases, la métrica sea 0 directamente y eliminar un Warning que indicaba justo eso\n",
        "           'recall': make_scorer(recall_score),\n",
        "           'f1_score': make_scorer(f1_score),\n",
        "           'hinge_loss': make_scorer(hinge_loss, greater_is_better=False),\n",
        "           # Utilizo la función de pérdida hinge_loss, con greater_is_better=False ya que por defecto las métricas\n",
        "           #de scikit-learn están configuradas para mazimizar su valor, y en la función de pérdida se minimiza\n",
        "           }\n",
        "\n",
        "#Ejecutar el algoritmo con valores distintos en sus parámetros\n",
        "CValues = [1, 5, 10]\n",
        "class_weight_values = [{0: 1, 1: 4},{0: 1, 1: 5},{0: 1, 1: 6}]\n",
        "max_iters = 10000\n",
        "\n",
        "\n",
        "for C in CValues:\n",
        "  for class_weight_val in class_weight_values:\n",
        "    # Crear el modelo de SVM con kernel lineal con los parámetros elegidos\n",
        "    SVC_modelo = SVC(\n",
        "        kernel='linear', # Tipo del kernel, utilizamos lineal para que el modelo sea lineal\n",
        "        max_iter = max_iters, #número máximo de iteraciones\n",
        "        random_state=1, # Establecer semilla para los numero aleatorios generados para\n",
        "        C = C, # parametro de reularización\n",
        "        tol = 1e-3, # tolerancia del criterio de parada por defecto\n",
        "        class_weight=class_weight_val # Determina los pesos de las clases\n",
        "        )\n",
        "    # Crear el objeto K-fold con 10 divisiones\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=10, # Número de particiones (folds)\n",
        "        random_state=0, # Semilla para los números aleatorios\n",
        "        shuffle=True #Desordenar por clases antes de particionar el conjunto\n",
        "        )\n",
        "    # Realizar validación cruzada y obtener los resultados de varias métricas\n",
        "    results = cross_validate(SVC_modelo, preproc_trainX, trainY, cv=kfold, scoring=scoringSVM)\n",
        "\n",
        "    #guardar datos para la tabla\n",
        "    CTabla.append(C)\n",
        "    class_weightTabla.append(class_weight_val)\n",
        "\n",
        "    accuracyTabla.append(results['test_accuracy'].mean())\n",
        "    precisionTabla.append(results['test_precision'].mean())\n",
        "    recallTabla.append(results['test_recall'].mean())\n",
        "    f1Tabla.append(results['test_f1_score'].mean())\n",
        "    funcionPerdidaTabla.append(-results['test_hinge_loss'].mean())#  Cambiar de signo la funcion de pérdida negativa\n",
        "\n",
        "\n",
        "#Crear DataFrame y mostrarlo\n",
        "tableFrame = pd.DataFrame({'Parámetro de regularización': CTabla,\n",
        "                          'Class weights (penalización de clases)': class_weightTabla,'Error de validación (función de pérdida)':funcionPerdidaTabla,\n",
        "                           'Accuracy':accuracyTabla,'Precision': precisionTabla,'Recall':recallTabla,'F1-Score':f1Tabla})\n",
        "display(tableFrame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "hqf1O2tDmByE",
        "outputId": "4fd92ac6-945c-434b-fc93-ad6bb9edaae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Parámetro de regularización Class weights (penalización de clases)  \\\n",
              "0                            1                           {0: 1, 1: 4}   \n",
              "1                            1                           {0: 1, 1: 5}   \n",
              "2                            1                           {0: 1, 1: 6}   \n",
              "3                            5                           {0: 1, 1: 4}   \n",
              "4                            5                           {0: 1, 1: 5}   \n",
              "5                            5                           {0: 1, 1: 6}   \n",
              "6                           10                           {0: 1, 1: 4}   \n",
              "7                           10                           {0: 1, 1: 5}   \n",
              "8                           10                           {0: 1, 1: 6}   \n",
              "\n",
              "   Error de validación (función de pérdida)  Accuracy  Precision    Recall  \\\n",
              "0                                  1.002418  0.937261   0.288333  0.023271   \n",
              "1                                  1.009418  0.930262   0.174524  0.033821   \n",
              "2                                  1.026983  0.912697   0.187420  0.135239   \n",
              "3                                  1.005472  0.934208   0.204365  0.029566   \n",
              "4                                  1.033850  0.905830   0.195746  0.179477   \n",
              "5                                  1.066180  0.873499   0.185600  0.305674   \n",
              "6                                  1.049248  0.890432   0.178606  0.221232   \n",
              "7                                  1.101801  0.837879   0.112013  0.238342   \n",
              "8                                  1.149664  0.790016   0.113292  0.368883   \n",
              "\n",
              "   F1-Score  \n",
              "0  0.042853  \n",
              "1  0.054485  \n",
              "2  0.151212  \n",
              "3  0.051405  \n",
              "4  0.181507  \n",
              "5  0.223883  \n",
              "6  0.192345  \n",
              "7  0.151000  \n",
              "8  0.172880  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bfb9465-c70a-4f48-8f37-de67a4d4f173\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Parámetro de regularización</th>\n",
              "      <th>Class weights (penalización de clases)</th>\n",
              "      <th>Error de validación (función de pérdida)</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>1.002418</td>\n",
              "      <td>0.937261</td>\n",
              "      <td>0.288333</td>\n",
              "      <td>0.023271</td>\n",
              "      <td>0.042853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>1.009418</td>\n",
              "      <td>0.930262</td>\n",
              "      <td>0.174524</td>\n",
              "      <td>0.033821</td>\n",
              "      <td>0.054485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>{0: 1, 1: 6}</td>\n",
              "      <td>1.026983</td>\n",
              "      <td>0.912697</td>\n",
              "      <td>0.187420</td>\n",
              "      <td>0.135239</td>\n",
              "      <td>0.151212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>1.005472</td>\n",
              "      <td>0.934208</td>\n",
              "      <td>0.204365</td>\n",
              "      <td>0.029566</td>\n",
              "      <td>0.051405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>1.033850</td>\n",
              "      <td>0.905830</td>\n",
              "      <td>0.195746</td>\n",
              "      <td>0.179477</td>\n",
              "      <td>0.181507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>{0: 1, 1: 6}</td>\n",
              "      <td>1.066180</td>\n",
              "      <td>0.873499</td>\n",
              "      <td>0.185600</td>\n",
              "      <td>0.305674</td>\n",
              "      <td>0.223883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>{0: 1, 1: 4}</td>\n",
              "      <td>1.049248</td>\n",
              "      <td>0.890432</td>\n",
              "      <td>0.178606</td>\n",
              "      <td>0.221232</td>\n",
              "      <td>0.192345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>{0: 1, 1: 5}</td>\n",
              "      <td>1.101801</td>\n",
              "      <td>0.837879</td>\n",
              "      <td>0.112013</td>\n",
              "      <td>0.238342</td>\n",
              "      <td>0.151000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>{0: 1, 1: 6}</td>\n",
              "      <td>1.149664</td>\n",
              "      <td>0.790016</td>\n",
              "      <td>0.113292</td>\n",
              "      <td>0.368883</td>\n",
              "      <td>0.172880</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bfb9465-c70a-4f48-8f37-de67a4d4f173')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bfb9465-c70a-4f48-8f37-de67a4d4f173 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bfb9465-c70a-4f48-8f37-de67a4d4f173');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para elgir los hiperparámtros con este nuevo modelo hay que seguir las mismas consideraciones que se han explicado con el modelo de Regresión Logística. Por lo tanto, siguiendo el mismo método, he considerado como mejor modelo el que se implementa con la constante de regularización $C= 1$ y la proporción de pesos ${0: 1, 1: 6}$. Este modelo es el tercer modelo con mejor valor en la métrica F1-Score, y por lo tanto tiene valores altos de Precision y Recall comparado con el resto y de entre los tres modelos con mejor F1-Score es el modelo con mayor Accuracy y función de pérdida."
      ],
      "metadata": {
        "id": "tuXL_7nmwAJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a comparar ambos modelos con los hiperparámetros elegidos y para ello vamos a utilizar a parte de las métricas calculadas la matriz de confusión entrenando con todo el conjunto de entrenamiento:"
      ],
      "metadata": {
        "id": "2KRdicoQys1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tipoRegul = 'l2'\n",
        "lr =0.01\n",
        "alpha = 0.001\n",
        "class_weight_val = {0: 1, 1: 4}\n",
        "\n",
        "\n",
        "# Crear el modelo de Regresión Logística SGD con los parámetros elegidos\n",
        "RL_SGD_modelo = SGDClassifier(\n",
        "  loss = 'log_loss', # Determinar lunción de pérdida asociada al modelo de regresión logística (log_loss)\n",
        "  max_iter = max_iters, #número máximo de iteraciones\n",
        "  random_state=1, # Establecer semilla para los numero aleatorios generados para desordenar los datos\n",
        "  shuffle = True, # Desordenar muestras después de cada época,\n",
        "  learning_rate = 'constant', # Determinar que el learning rate sea constante, elegido por parámetro eta0\n",
        "  eta0 = lr, # Elegir tasa de aprendizaje constante que utilizará SGD\n",
        "  penalty = tipoRegul, # Elegir tipo de regularización\n",
        "  alpha = alpha, # parametro de reularización\n",
        "  tol = 1e-3, # tolerancia del criterio de parada\n",
        "  class_weight=class_weight_val #ajusta automáticamente los pesos de las clases en función de su frecuencia en los datos de entrenamiento\n",
        "  )\n",
        "\n",
        "# Crear el objeto K-fold con 10 divisiones\n",
        "kfold = StratifiedKFold(\n",
        "  n_splits=10, # Número de particiones (folds)\n",
        "  random_state=0, # Semilla para los números aleatorios\n",
        "  shuffle=True #Desordenar por clases antes de particionar el conjunto\n",
        "  )\n",
        "# Realizar validación cruzada y obtener los resultados de varias métricas\n",
        "results = cross_validate(RL_SGD_modelo, preproc_trainX, trainY, cv=kfold, scoring=scoringRL)\n",
        "\n",
        "print('Modelo de Regresión Lineal SGD:')\n",
        "print('Tasa de aprendizaje',lr)\n",
        "print('Class weights (penalización de clases)',class_weight_val)\n",
        "print('Parámetro de regularización (alpha)',alpha)\n",
        "print('Exactitud promedio:', results['test_accuracy'].mean())\n",
        "print('Precisión promedio:', results['test_precision'].mean())\n",
        "print('Recall promedio:', results['test_recall'].mean())\n",
        "print('F1-Score promedio:', results['test_f1_score'].mean())\n",
        "print('Error de validación (Función de Pérdida Log_loss):', -results['test_neg_log_loss'].mean()) #  Cambiar de signo la funcion de pérdida negativa\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "RL_SGD_modelo.fit(preproc_trainX, trainY)\n",
        "\n",
        "# Obtener las predicciones del modelo\n",
        "y_pred = RL_SGD_modelo.predict(preproc_trainX)\n",
        "\n",
        "# Crear la matriz de confusión\n",
        "cm = confusion_matrix(trainY, y_pred)\n",
        "\n",
        "# Crear un DataFrame de pandas con la matriz de confusión\n",
        "df_cm = pd.DataFrame(cm, index=['Clase real 0', 'Clase real 1'], columns=['Predicción Clase 0', 'Predicción Clase 1'])\n",
        "\n",
        "print('Matriz de Confusión:')\n",
        "\n",
        "# Mostrar la tabla\n",
        "display(df_cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "y5OzJ_eBQyEN",
        "outputId": "d05b4a28-5625-46d8-d4e6-bbf778e6117a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo de Regresión Lineal SGD:\n",
            "Tasa de aprendizaje 0.01\n",
            "Class weights (penalización de clases) {0: 1, 1: 4}\n",
            "Parámetro de regularización (alpha) 0.001\n",
            "Exactitud promedio: 0.9166392765109157\n",
            "Precisión promedio: 0.26918349068915726\n",
            "Recall promedio: 0.17340425531914894\n",
            "F1-Score promedio: 0.1878475526022446\n",
            "Error de validación (Función de Pérdida Log_loss): 0.2849347391068845\n",
            "Matriz de Confusión:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              Predicción Clase 0  Predicción Clase 1\n",
              "Clase real 0                7274                 110\n",
              "Clase real 1                 427                  47"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d58ea22d-c1ac-4815-b7bd-5886cd601864\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicción Clase 0</th>\n",
              "      <th>Predicción Clase 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Clase real 0</th>\n",
              "      <td>7274</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Clase real 1</th>\n",
              "      <td>427</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d58ea22d-c1ac-4815-b7bd-5886cd601864')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d58ea22d-c1ac-4815-b7bd-5886cd601864 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d58ea22d-c1ac-4815-b7bd-5886cd601864');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignorar el warning ConvergenceWarning para que la salida esté más clara\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "max_iters = 10000\n",
        "C=1\n",
        "class_weight_val ={0: 1, 1: 6}\n",
        "\n",
        "# Crear el modelo de SVM con kernel Lineal con los parámetros elegidos\n",
        "SVC_modelo = SVC(\n",
        "  kernel='linear', # Tipo del kernel, utilizamos lineal para que el modelo sea lineal\n",
        "  max_iter = max_iters, #número máximo de iteraciones\n",
        "  random_state=1, # Establecer semilla para los numero aleatorios generados para\n",
        "  C = C, # parametro de reularización\n",
        "  tol = 1e-3, # tolerancia del criterio de parada por defecto\n",
        "  class_weight=class_weight_val # Determina los pesos de las clases\n",
        "  )\n",
        "\n",
        "# Crear el objeto K-fold con 10 divisiones\n",
        "kfold = StratifiedKFold(\n",
        "  n_splits=10, # Número de particiones (folds)\n",
        "  random_state=0, # Semilla para los números aleatorios\n",
        "  shuffle=True #Desordenar por clases antes de particionar el conjunto\n",
        "  )\n",
        "# Realizar validación cruzada y obtener los resultados de varias métricas\n",
        "results = cross_validate(SVC_modelo, preproc_trainX, trainY, cv=kfold, scoring=scoringSVM)\n",
        "print('Modelo SVM con Kernel Lineal:')\n",
        "print('C',C)\n",
        "print('class_weight_val',class_weight_val)\n",
        "print('Exactitud promedio:', results['test_accuracy'].mean())\n",
        "print('Precisión promedio:', results['test_precision'].mean())\n",
        "print('Recall promedio:', results['test_recall'].mean())\n",
        "print('F1-Score promedio:', results['test_f1_score'].mean())\n",
        "print('Error de validación (Función de Pérdida hinge_loss):', -results['test_hinge_loss'].mean()) #  Cambiar de signo la funcion de pérdida negativa\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "SVC_modelo.fit(preproc_trainX, trainY)\n",
        "\n",
        "# Obtener las predicciones del modelo\n",
        "y_pred = SVC_modelo.predict(preproc_trainX)\n",
        "\n",
        "# Crear la matriz de confusión\n",
        "cm = confusion_matrix(trainY, y_pred)\n",
        "\n",
        "# Crear un DataFrame de pandas con la matriz de confusión\n",
        "df_cm = pd.DataFrame(cm, index=['Clase real 0', 'Clase real 1'], columns=['Predicción Clase 0', 'Predicción Clase 1'])\n",
        "\n",
        "print('Matriz de Confusión:')\n",
        "# Mostrar la tabla\n",
        "display(df_cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "344f1d32-8357-4bb1-df27-bc47b2d1a1eb",
        "id": "wuj0THcNFUpy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo SVM con Kernel Lineal:\n",
            "C 1\n",
            "class_weight_val {0: 1, 1: 6}\n",
            "Exactitud promedio: 0.9126967148020292\n",
            "Precisión promedio: 0.18741978638837722\n",
            "Recall promedio: 0.13523936170212764\n",
            "F1-Score promedio: 0.15121194092992304\n",
            "Error de validación (Función de Pérdida hinge_loss): 1.0269827069253334\n",
            "Matriz de Confusión:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              Predicción Clase 0  Predicción Clase 1\n",
              "Clase real 0                7209                 175\n",
              "Clase real 1                 401                  73"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9f1e8a0-cdee-4eec-aa14-e7a4fed9706f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicción Clase 0</th>\n",
              "      <th>Predicción Clase 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Clase real 0</th>\n",
              "      <td>7209</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Clase real 1</th>\n",
              "      <td>401</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9f1e8a0-cdee-4eec-aa14-e7a4fed9706f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9f1e8a0-cdee-4eec-aa14-e7a4fed9706f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9f1e8a0-cdee-4eec-aa14-e7a4fed9706f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando Ambos modelos, podemos ver que el modelo de Regresión Logística ha obtenido unas evaluaciones ligeramente mejores durante la validación, en términos de las métrcias ya que al utilizar funciones de pérdidad distintas no se pueden comapra en ese aspecto. Aun así, como la diferencia de las valoraciones es mínima, los dos modelos han obtenido prácticamente los mismos resultados, y por tanto se podría elegir el modelo que se quisiera. Sin embargo, observando las matrices de confusión de cada modelo en el conjunto de entrenamiento, se puede ver que el modelo SVM ha clasificado correctamente más muestras de la clase minoritaria que el modelo de Regresión Logística, y al haber tanto desequilibrio entre ambas clases voy a elegir el modelo SVM como modelo final y mejor hipótesis para el problema."
      ],
      "metadata": {
        "id": "miZAEO2uB0zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por lo tanto ahora vamos a utilizar el conjunto de datos de test para evaluar el modelo elegido y estimar el error $E_{out}$ final del modelo:"
      ],
      "metadata": {
        "id": "U5yIE3xAFL9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Obtener las predicciones del modelo utilizando los datos de test\n",
        "y_pred = SVC_modelo.predict(preproc_testX)\n",
        "\n",
        "# Calcular la precisión utilizando los datos de test\n",
        "precision = precision_score(testY, y_pred)\n",
        "\n",
        "# Calcular la exactitud (accuracy)  utilizando los datos de test\n",
        "accuracy = accuracy_score(testY, y_pred)\n",
        "\n",
        "# Calcular recall    utilizando los datos de test\n",
        "recall = recall_score(testY, y_pred)\n",
        "\n",
        "# Calcular el F1-Score  utilizando los datos de test\n",
        "f1 = f1_score(testY, y_pred)\n",
        "\n",
        "# Calcular el F1-Score utilizando los datos de test\n",
        "hinge_loss_value = hinge_loss(testY, y_pred)\n",
        "\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Accuracy en test:\", accuracy)\n",
        "print(\"Recall en test:\", recall)\n",
        "print(\"Precisión en test:\", precision)\n",
        "print(\"F1-Score en test:\", f1)\n",
        "print(\"Error de test (Función de Pérdida hinge_loss):\", hinge_loss_value)\n",
        "\n",
        "# Crear la matriz de confusión\n",
        "cm = confusion_matrix(testY, y_pred)\n",
        "\n",
        "# Crear un DataFrame de pandas con la matriz de confusión\n",
        "df_cm = pd.DataFrame(cm, index=['Clase real 0', 'Clase real 1'], columns=['Predicción Clase 0', 'Predicción Clase 1'])\n",
        "\n",
        "print('Matriz de Confusión:')\n",
        "# Mostrar la tabla\n",
        "display(df_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "s2pKCaboCLEH",
        "outputId": "a3854d42-a0f2-4269-e052-187ea0ce7c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy en test: 0.9215885947046843\n",
            "Recall en test: 0.16071428571428573\n",
            "Precisión en test: 0.23076923076923078\n",
            "F1-Score en test: 0.18947368421052632\n",
            "Error de test (Función de Pérdida hinge_loss): 1.0213849287169043\n",
            "Matriz de Confusión:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              Predicción Clase 0  Predicción Clase 1\n",
              "Clase real 0                1792                  60\n",
              "Clase real 1                  94                  18"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef58267d-5188-4b8d-92c2-00b11668c98b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicción Clase 0</th>\n",
              "      <th>Predicción Clase 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Clase real 0</th>\n",
              "      <td>1792</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Clase real 1</th>\n",
              "      <td>94</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef58267d-5188-4b8d-92c2-00b11668c98b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef58267d-5188-4b8d-92c2-00b11668c98b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef58267d-5188-4b8d-92c2-00b11668c98b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar en los resultados del modelo que se ha obtenido un buen resultado ya que los valores de las métricas y de la función de pérdida obtenidos en test son muy próximos a los valores obtenidos en entrenamiento y en validación y por tanto se ha conseguido generalizar el problema y obtener buenos resultados ajustando modelo y eligiendo los parámetros correctos. Para evaluar el modelo a partir de estos resultados es necesario tener en consideración que los modelos que hemos implementado son lineales y por tanto están más limitados a la hora de ajustarse al conjunto de muestras de entrenamiento que otros modelos más potentes como los modelos no lineales que podrían obtener mejores resultados en entrenamiento. Si no se ha podido obtener un mejor resultado que este puede ser por las limitaciones de los modelos lineales y no necesariamente por haber ajustado y generalizado el problema de forma incorrecta."
      ],
      "metadata": {
        "id": "8m1A9zowHDGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>8)  Construya las curvas de aprendizaje del modelo, y discuta la calidad del ajuste obtenido a la vista de la conducta de dichas curvas. 0.5 puntos."
      ],
      "metadata": {
        "id": "3R044TTvg9Zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a crear las curvas de aprendizaje del modelo elegido separando de nuevo el conjunto de entrenamiento en un nuevo conjunto de validación del 20% y otro conjunto de entrenamiento del 80%, de forma parecida a como se hizo con el conjunto total de datos. Después voy a entrenar el modelo con un conjunto de datos inicialmente pequeño y obtengo el error de validación junto con el de entrenamiento, y cada iteración repito lo mismo pero con un sunconjunto de datos mayor obtenido del conjunto de entrenamiento hasta utilizar el conjunto de datos total. Finalmente se crear las curvas de los errores $E_{in}$ de entrenamiento y $E_{out}$ estimado a partid del error obtenido del conjunto de validación."
      ],
      "metadata": {
        "id": "vsbn-BmXJTYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_iters = 10000\n",
        "C=1\n",
        "class_weight_val ={0: 1, 1: 6}\n",
        "\n",
        "# Crear el modelo de SVM con kernel lineal con los parámetros elegidos\n",
        "SVC_modelo_Curvas = SVC(\n",
        "  kernel='linear', # Tipo del kernel, utilizamos lineal para que el modelo sea lineal\n",
        "  max_iter = max_iters, #número máximo de iteraciones\n",
        "  random_state=1, # Establecer semilla para los numero aleatorios generados para\n",
        "  C = C, # parametro de reularización\n",
        "  tol = 1e-3, # tolerancia del criterio de parada por defecto\n",
        "  class_weight=class_weight_val # Determina los pesos de las clases\n",
        "  )\n",
        "\n",
        "trainPortion = 0.8 #porcentaje de train, el porcentaje de validacion será la resta de 1 menos el porcentaje de train\n",
        "\n",
        "indexesData = np.arange(len(trainY)) #Indices del conjunto de muestras\n",
        "\n",
        "np.random.shuffle(indexesData) #Desordenar indices de las muestras\n",
        "numberTrain = round(len(indexesData)*trainPortion) #numero de muestras para train\n",
        "trainIndexes = indexesData[:numberTrain]\n",
        "valIndexes = indexesData[numberTrain:]\n",
        "\n",
        "E_in = []\n",
        "E_out = []\n",
        "ejeX = []\n",
        "numiters = 50\n",
        "for i in range(1,numiters):\n",
        "  ejeX.append(i*len(trainIndexes)//numiters)\n",
        "  # Entrenar el modelo con los datos de entrenamiento\n",
        "  SVC_modelo_Curvas.fit(preproc_trainX[trainIndexes[:i*len(trainIndexes)//numiters]], trainY[trainIndexes[:i*len(trainIndexes)//numiters]])\n",
        "  # Obtener error en entrenamiento\n",
        "  y_pred = SVC_modelo_Curvas.predict(preproc_trainX[trainIndexes[:i*len(trainIndexes)//numiters]])\n",
        "  E_in.append(hinge_loss(trainY[trainIndexes[:i*len(trainIndexes)//numiters]], y_pred))\n",
        "  # Obtener error en validación\n",
        "  y_pred = SVC_modelo_Curvas.predict(preproc_trainX[valIndexes])\n",
        "  E_out.append(hinge_loss(trainY[valIndexes], y_pred))\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Curvas de Aprendizaje\")\n",
        "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
        "plt.ylabel(\"Error (función de pérdida SVM hinge)\")\n",
        "plt.plot(ejeX, E_out, 'r',label=r'$E_{out}$')\n",
        "plt.plot(ejeX, E_in, 'b',label=r'$E_{in}$')\n",
        "\n",
        "plt.legend(fontsize = 12) # poner el tamaño de la leyenda como en el resultado dado\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "139e7ff3-3786-4e17-a8a4-3b5889b17e33",
        "id": "00subrZC8_XB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar en el gráfico de las curvas de aprendizaje que el modelo se comporta de forma correcta ajustandose al problema y obteniendo una buena generalización a medida que aumenta el tamaño del conjunto de muestras. Cuantos más datos se usan para entrenar el modelo, más generalización se consigue (al tener más información del problema y de la función objetivo) y por tanto el error $E_{out}$ se acerca cada vez más al error $E_{in}$. El modelo lineal es capaz de ajustar mejor los datos cuanto menos haya, ya que al haber menos datos, el modelo tiene que predecir menos muestras y entonces puede ajustarse mejor a una cantidad menor de datos, por lo tanto el error $E_{in}$ aumenta con el tamaño del conjunto de entrenamiento. Por otro lado, cuantos más muestras se tienen, más información se tiene del problema y por tanto se puede obtener una mayor generalización de la función objetivo obteniendo un error $E_{out}$ menor a medida que aumenta el tamaño del conjunto de muestras. Es por esto que los errores $E_{in}$ y $E_{out}$ tienden a acercarse y converger a medida que aumenta el tamaño del conjunto de entrenamiento.   \n",
        "A partir de estos resultados, podemos establecer que, aunque seguramente no sea el modelo con el que se obtienen los mejores resultados, ya que los modelos no lineales son más potentes, este modelo ha conseguido ajustarse en cierta medida al problema y aprender cierta variabilidad consiguiendo generalizar el resultado obtenido fuera del entrenamiento. Esto se puede observar principalmente en la disminución del error $E_{out}$ a medida que aumenta el tamaño del conjunto de entrenamiento, ya que cuanta más información se le ofrece al modelo para entrenar, mejoes resultados y error $E_{out}$ obtiene y por tanto más aprende."
      ],
      "metadata": {
        "id": "snfIDa9nVGR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>9)  Suponga ahora que Ud. debe realizar este ajuste para una empresa que le ha proporcionado los datos, sin distinción entre training y test. ¿Cúal sería el mejor modelo que les propondría, y qué error  $E_{out}$ les diría que tiene? Justifique todas las decisiones. 0.5 puntos."
      ],
      "metadata": {
        "id": "E_x9IPmEg_RX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tal y como he realizado en esta práctica, realizaría los siguientes pasos:\n",
        "\n",
        "\n",
        "1.   Separar el conjunto de datos en una parte de entrenameinto y otra de test\n",
        "2.   Analizar el problema observando de donde proceden los datos, que variables se utilizan y de que tipo, como se han extraido los datos y elegir los modelos que se pretenden usar para ajustar este problema específico.\n",
        "3.   Analizar el conjunto de datos de training para tratar de encontrar variables constantes, desequilibrio en las clases y cualquier peculiaridad más del conjunto de entrenamiento.\n",
        "4.   Preprocesar los datos codificando las varaibles que sean necesarias como las categóricas, escalar los datos y aplicar cualquier procesamiento necesario al conjutno de datos.\n",
        "5.   Establecer la técnica de Validación cruzada eligiendo el número de particiones si los datos son suficientes como para permitirlo.\n",
        "6.   Establecer las métrcias que son necesarias dependiendo del conjunto de datos y los hiperparámetros que se van a escoger experimentalmente junto con la regularización elegida para el conjutno de datos en concreto.\n",
        "7.   Realiza la técnica de Validación cruzada para elegir los hiperparámetros de los modelos y evaluar los resultados para obtener la mejor hipótesis final para el problema.\n",
        "8.   Estimar el error  $E_{out}$ a partir del conjunto de test y evaluar los resultados obtenidos finales. Este modelo sería el modelo que se porpondría a la empresa junto con el error $E_{out}$ estimado a partir del error $E_{test}$.\n",
        "\n",
        "Durante los apartados anteriores he explicado los motivos que me han llevado a tomar cada decisión justificando las ventajas y desventajas de realizar cada paso.\n",
        "\n",
        "\n",
        "\n",
        "El error $E_{out}$ sería una estimación de este error a partir del error $E_{test}$ obtenido mediante el conjunto de test que he separado de los datos que me ofrece la empresa. Por lo tanto el error $E_{out}$ sería el error $E_{test}$ que obtengo a partir de mi modelo final que he elegido como mejor modelo. Este estimador del error $E_{out}$ es el mejor estimador debido a la teoría de la dimensión de Vapink-Chervonenkis junto con la teoría desarrollada en torno a la desigualdad de Hoeffding que ofrecen unas cotas del error $E_{out}$ en torno a los valores que se pueden obtener de los errores $E_{test}$ y $E_{in}$. Sin embargo, el uso de un conjunto de test implica un entrenamiento del modelo con un conjunto de datos menor, lo que afectará a la generalización y ajuste del prblema y por lo tanto a los resultados obtenidos. Cuanto mayor sea el conjunto de test, mejor será la estimación del error $E_{out}$ y peores resultado de entrenameinto se obtendrán, es por eso que se debe elgir un equilibrio entre una mejor estimación y un entrenamiento mejor.  \n",
        "\n",
        "En algunos casos, si los datos son escasos o se considera que no son suficientes, se podría utilizar todo el conjunto de datos como entrenamiento y estimar el error $E_{out}$ a partir del error $E_{in}$ del entrenamiento. Este es el caso extremo de obtener un peor estimador pero entrenar con un conjunto mayor de datos puede dar lugar a obtener mejores resultados en el ajuste del modelo.\n",
        "\n",
        "Esto ocurre también con Cross-Validation donde se utiliza una parte del conjunto de entrenamiento para validar y obtener una estimación del error del modelo. Al realizar diversas particiones y estimar con un conjunto de validación distinto cada vez se puede obtener un buen estimador del error realizando el promerdio de todas las particiones pero esto conlleva un aumento del coste computacional a parteque puede dificultar el proceso de aprendizaje del modelo.\n",
        "\n",
        "En el problema que se ha tratado de resolver mediante aprendizaje automático en los apartados anteriores, he explicado cuál era el mejor modelo que se ha conseguido obtener y yo propondría ese modelo para resolver este problema con el error $E_{out}$ que se ha estimado a partir del error $E_{test}$. Si además se disponde del conjunto de test, yo, personalmente, ofrecería como error del modelo el error $E_{test}$ obtenido a partir del modelo entrenado con los datos de entrenamiento, y después volvería a entrenar el modelo con el conjunto total de los datos (test incluido) y ofrecería ese modelo como modelo final. Como este modelo ha sido entrenado con una cantidad mayor de datos, el error proprocionado $E_{test}$ será una cota superior del error $E_{out}$ del modelo final y por tanto el error ofrecido será pesimista. Si por el contrario no se disponde del conjunto de test y la empresa se encarga de realiza el test conotro conjunto de datos, aun así del conjunto que se disponde crearía mis propias particiones como se ha comentado antes en entrenameinto y test y se haría el mismo proceso siguiendo los pasos."
      ],
      "metadata": {
        "id": "ne9xMXuEXy79"
      }
    }
  ]
}